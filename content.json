{"meta":{"title":"斑斓的梦","subtitle":"Zhen's Blog","description":"个人技术博客","author":"P.Zhen","url":"http://pzhen.github.io"},"pages":[{"title":"Categories","date":"2017-07-21T06:36:21.000Z","updated":"2017-07-21T06:36:21.000Z","comments":true,"path":"categories/index.html","permalink":"http://pzhen.github.io/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2017-07-21T06:56:32.000Z","updated":"2017-07-20T03:01:43.000Z","comments":true,"path":"about/index.html","permalink":"http://pzhen.github.io/about/index.html","excerpt":"","text":"&emsp;&emsp;Hi，欢迎来到我的博客，作者是一名coder。 13年毕业，毕业后一直在我大帝都从事PHP开发工作。 性格还算开朗。 梦想嘛，成为一名后端架构师，虽然路比较远，但是万一实现了呢， O(∩_∩)O哈哈~ 爱好广泛，羽毛球、游泳、爬山、跑步、骑单车、旅游、读书、玩游戏…… 技术方面，还是比较能折腾，喜欢PHP，喜欢Python，也喜欢Golang。 &emsp;&emsp;新的起点，爱技术，爱生活，爱读书。“给自己一个机会，给自己一次改变”，在这里希望有些知识可以帮助到更多的人，希望能记录下生活的点滴。“就算路不坦荡，也要做自己的太阳”，希望自己可以走的更远，你我共勉。"},{"title":"Tags","date":"2017-07-21T06:36:27.000Z","updated":"2017-07-21T06:36:27.000Z","comments":true,"path":"tags/index.html","permalink":"http://pzhen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Es - 单机多节点集群","slug":"Elasticsearch-单机多节点集群","date":"2017-07-21T08:11:43.000Z","updated":"2017-07-21T08:21:01.000Z","comments":true,"path":"2017/07/21/Elasticsearch-单机多节点集群/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Elasticsearch-单机多节点集群/","excerpt":"","text":"采用版本1.物理机 Mac 2.Elasticsearch 2.3.0 3.插件：head，bigdesk 4.部署4个节点：2个数据节点，1个主节点，1个备用主节点 部署请到 GitHub 下载 ES 2.3.0 版本 https://github.com/elastic/elasticsearch/tree/v2.3.0 解压请根据自己部署软件的习惯解压到合适目录，下面是我的本机目录： /Users/zhen/opt/es-cloud-2.3.0 es-cloud-2.3.0 文件夹放置的单机的4个节点目录，附上我的目录结构： 从图中大家也了解了，其实就是复制出4份来，只不过每个ES里面的配置不一样。 插件安装前面已经介绍过了，请看 这里 ，可以先安装master的插件，安转完成再复制就好了。 各个节点的配置主节点master： 123456789101112131415cluster.name: my-es#主节点node.name: masternode.master: true#数据节点node.data: falsenetwork.host: 0.0.0.0http.port: 9200transport.tcp.port: 9300#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 数据节点data-1： 123456789101112131415cluster.name: my-es#主节点node.name: data-1node.master: false#数据节点node.data: truenetwork.host: 0.0.0.0http.port: 9201transport.tcp.port: 9301#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 数据节点data-2： 123456789101112131415cluster.name: my-es#主节点node.name: data-2node.master: false#数据节点node.data: truenetwork.host: 0.0.0.0http.port: 9202transport.tcp.port: 9302#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 备用主节点： 123456789101112131415cluster.name: my-es#主节点node.name: client-1node.master: true#数据节点node.data: falsenetwork.host: 0.0.0.0http.port: 9203transport.tcp.port: 9303#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 启动启动节点，写到脚本里面执行，不用一条条的运行了。 1234567./es-node-master/bin/elasticsearch -d./es-node-data-1/bin/elasticsearch -d./es-node-data-2/bin/elasticsearch -d./es-node-client/bin/elasticsearch -d 查看集群状态： 测试假如我们挂掉主节点，再来看看我们的集群状态。 当我们挂掉了master，访问任意一个节点的head插件，来看集群状态。选举了client-1为主节点。 最后附上bigdesk的截图：","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Ik","slug":"Ik","permalink":"http://pzhen.github.io/tags/Ik/"},{"name":"集群","slug":"集群","permalink":"http://pzhen.github.io/tags/集群/"}]},{"title":"Mac 安装 Maven","slug":"Mac-安装-Maven","date":"2017-07-21T08:04:51.000Z","updated":"2017-07-21T08:06:46.000Z","comments":true,"path":"2017/07/21/Mac-安装-Maven/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Mac-安装-Maven/","excerpt":"","text":"1.下载maven http://mirror.bit.edu.cn/apache/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.zip 2.解压 unzip apache-maven-3.5.0-bin.zip 如果是tar.gz包 tar xzvf apache-maven-3.5.0-bin.tar.gz 3.配置环境变量 vim ~/.bash_profile 添加路径： export PATH=/路径/apache-maven-3.5.0/bin:$PATH 4.查看 mvn -version 官方install地址：http://maven.apache.org/install.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Maven","slug":"Linux/Maven","permalink":"http://pzhen.github.io/categories/Linux/Maven/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Maven","slug":"Maven","permalink":"http://pzhen.github.io/tags/Maven/"},{"name":"Java","slug":"Java","permalink":"http://pzhen.github.io/tags/Java/"}]},{"title":"Python 优先级队列","slug":"Python-优先级队列","date":"2017-07-21T07:22:32.000Z","updated":"2017-07-21T07:58:18.000Z","comments":true,"path":"2017/07/21/Python-优先级队列/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Python-优先级队列/","excerpt":"优先级队列是一种容器型数据结构，它能管理一队记录，并按照排序字段（例如一个数字类型的权重值）为其排序。由于是排序的，所以在优先级队列中你可以快速获取到最大的和最小的值。","text":"优先级队列是一种容器型数据结构，它能管理一队记录，并按照排序字段（例如一个数字类型的权重值）为其排序。由于是排序的，所以在优先级队列中你可以快速获取到最大的和最小的值。你可以认为优先级队列是一种修改过的普通队列：普通队列依据记录插入的时间来获取下一个记录，优先级队列依据优先级来获取下一个记录，而优先级取决于排序字段的值。 优先级队列经常用来解决调度问题，比如给更紧急的任务更高的优先级。 我们以操作系统的任务调度为例：高优先级的任务（比如实时游戏）应该先于低优先级的任务（比如后台下载软件更新）执行。通过在优先级队列中依据任务的紧急程度排序，我们能让最紧急的任务优先得到执行。 queue.PriorityQueue类 12345678910111213141516import Queueq = Queue.PriorityQueue()q.put((2,'code'))q.put((1,'eat'))q.put((3,'sleep'))while not q.empty(): next_item = q.get() print(next_item)# Result# (1,'eat')# (2, 'code')# (3, 'sleep') 这个优先级队列内部使用了heapq，所以它的时间复杂度和heapq是相同的。 不同的是PriorityQueue的操作是同步的，提供锁操作，支持并发的生产者和消费者。 依据使用场景，它可能很有用，也可能有点太大了。通常来说它的基于类接口要比heapq的基于函数的接口更友好。","categories":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/tags/Python/"},{"name":"队列","slug":"队列","permalink":"http://pzhen.github.io/tags/队列/"},{"name":"优先级队列","slug":"优先级队列","permalink":"http://pzhen.github.io/tags/优先级队列/"}]},{"title":"Shell 正则表达式","slug":"Shell-正则表达式","date":"2017-07-21T07:06:47.000Z","updated":"2017-07-21T07:11:30.000Z","comments":true,"path":"2017/07/21/Shell-正则表达式/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Shell-正则表达式/","excerpt":"","text":"正则表达式的分类 基本的正则表达式（Basic Regular Expression 又叫Basic RegEx 简称BREs） 扩展的正则表达式（Extended Regular Expression 又叫Extended RegEx 简称EREs） Perl的正则表达式（Perl Regular Expression 又叫Perl RegEx 简称PREs） 基本组成部分正则表达式的基本组成部分。 POSIX字符类POSIX字符类是一个形如[:…:]的特殊元序列（meta sequence），他可以用于匹配特定的字符范围。 元字符元字符（meta character）是一种Perl风格的正则表达式，只有一部分文本处理工具支持它，并不是所有的文本处理工具都支持。 文章来源：http://man.linuxde.net/docs/shell_regex.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"正则","slug":"正则","permalink":"http://pzhen.github.io/tags/正则/"}]},{"title":"grep 简单用法","slug":"grep-简单用法","date":"2017-07-21T07:02:22.000Z","updated":"2017-07-21T07:04:29.000Z","comments":true,"path":"2017/07/21/grep-简单用法/","link":"","permalink":"http://pzhen.github.io/2017/07/21/grep-简单用法/","excerpt":"","text":"是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。我经常用来查找字符串比如： 1grep -rn \"字符串\" . 递归查找当前目录下所有文件中 “字符串” 并且所在标出所在行。 下面来看看具体参数：12345678grep [-acinv] [--color=auto] '搜寻字符串' filename 选项参数:-a :将 binary 档案以 text 档案方式搜寻数据-c :计算找刡 '搜寻字符串' 次数-i :忽略大小写-n :输出行号-v :反向选择，亦即显示出没有 '搜寻字符串' 内容癿那一行! --color=auto :可以将找刡癿关键词部分加上颜色癿显示!-A :后面可加数字，为 after 癿意思，除了列出该行外，后续的 n 行也列出; -B :后面可加数字，为 befer 癿意思，除了列出该行外，前面的 n 行也列出; grep 只支持基础正则表示法，若要延伸型正则，则要用egrep或者 grep -E。 基础正则表示法总结如下： 123456789^word：查找字符串(word)在行首 grep -n '^word' filenameword$: 查找字符串(word)在行末 grep -n 'word$' filename. : 任意字符\\ : 转译*：前面字符 0 到 任意多个[] : 字符集合[n1-n2] : 范围 如[0-9][^]: 字符取反，就是不能是里面的字符\\&#123;n,m\\&#125;: 出现n到m次 延伸正则表示总结如下： 12345+ ：一个或者一个以上？ ：零个或者一个| ： 或() : 群组 egrep -n 'g(la|oo)d' filename 找出 glad 或者 good 两个字符串()+: 群组出现一次或者多次 grep 还有很多高级用法，请感兴趣的自己去补给，我只列出了基础的常见的用法。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"Grep","slug":"Grep","permalink":"http://pzhen.github.io/tags/Grep/"}]},{"title":"Hexo 'Deployer not found'","slug":"Hexo-Deployer-not-found","date":"2017-07-21T06:03:27.000Z","updated":"2017-07-21T06:08:32.000Z","comments":true,"path":"2017/07/21/Hexo-Deployer-not-found/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Hexo-Deployer-not-found/","excerpt":"","text":"重新部署了Hexo，结果无法部署，解决方法如下： 1npm install hexo-deployer-git --save","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://pzhen.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://pzhen.github.io/tags/Hexo/"}]},{"title":"Es – 集群生态总结","slug":"Elasticsearch-–-集群生态总结","date":"2017-07-20T09:05:22.000Z","updated":"2017-07-20T09:28:15.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-集群生态总结/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-集群生态总结/","excerpt":"","text":"分片算法:1shard = hash(routing) % number_of_primary_shards routing值是一个任意字符串，它默认是_id但也可以自定义，这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数的范围永远是0到number_of_primary_shards – 1，这个数字就是特定文档所在的分片。 这也解释了为什么主切片的数量只能在创建索引时定义且不能修改：如果主切片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。 所有的文档API（get、index、delete、bulk、update、mget）都接收一个routing参数，它用来自定义文档到分片的映射。自定义路由值可以确保所有相关文档.比如用户的文章,按照用户账号路由,就可以实现属于同一用户的文档被保存在同一分片上。 增删改（write）执行过程不管是索引，还是文档的write操作，它们必须在主分片上成功完成才能复制到相关的复制分片上,下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤： 1、客户端给Node 1发送新建、索引或删除请求。 2、节点使用文档的_id确定文档属于分片0。它转发请求到Node 3，分片0位于这个节点上。 3、Node 3在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1和Node 2的复制节点上。当所有的复制节点报告成功，Node 3报告成功到请求的节点，请求的节点再报告给客户端。 客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。 副本分片复制时的相关的参数说明:replication: 复制默认的值是sync。这将导致主分片得到复制分片的成功响应后才返回，如果你设置replication为async，请求在主分片上被执行后就会返回给客户端。它依旧会转发请求给复制节点，但你将不知道复制节点成功与否。 默认的sync复制允许Elasticsearch强制反馈传输。async复制可能会因为在不等待其它分片就绪的情况下发送过多的请求而使Elasticsearch过载。 consistency: 默认主分片在尝试写入时需要规定数量(quorum)或过半的分片（可以是主节点或复制节点）可用。这是防止数据被写入到错的网络分区。规定的数量计算公式如下：1int( (primary + number_of_replicas) / 2 ) + 1 consistency允许的值为one（只有一个主分片），all（所有主分片和复制分片）或者默认的quorum或过半分片。 注意number_of_replicas是在索引中的的设置，用来定义复制分片的数量，而不是现在活动的复制节点的数量。如果你定义了索引有3个复制节点，那规定数量是：int( (primary + 3 replicas) / 2 ) + 1 = 3 但如果你只有2个节点，那你的活动分片不够规定数量，也就不能索引或删除任何文档。 注意: 新索引默认有1个复制分片，这意味着为了满足quorum的要求需要两个活动的分片。当然，这个默认设置将阻止我们在单一节点集群中进行操作。为了避开这个问题，规定数量只有在number_of_replicas大于一时才生效。 timeout： 当分片副本不足时Elasticsearch会等待更多的分片出现。默认等待一分钟。如果需要，你可以设置timeout参数让它终止的更早：100表示100毫秒，30s表示30秒。 集群生态:1.同集群中节点之间可以扩容缩容, 2.主分片的数量会在其索引创建完成后修正，但是副本分片的数量会随时变化。 3.相同的分片不会放在同一个节点上. 集群健康:在Elasticsearch集群中可以监控统计很多信息，但是只有一个是最重要的时集群健康(cluster health)。Es中用三种颜色状态表示:green，yellow，red. Green：所有主分片和副本分片都可用 Yellow：所有主分片可用，但不是所有副本分片都可用 Red：不是所有的主分片都可用； 单机多节点来了解ES的高可用创建单集群节点如图我们的单点集群: 实例中我们创建一个索引dobbyindex.一个索引默认指派5个主分片,实例中我们设定4个主分片和2个复制分片（每个主分片有2个复制分片对应）： 1234567PUT /dobbyindex&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 4, &quot;number_of_replicas&quot;: 2 &#125;&#125; 创建后索引如图: 在节点es-node1中片的存放如下: 我们的主分片都被分配到了es-node1.但是我们的8个复制分片还没有被分配到节点上, 此时的集群健康状况如下: cluster health: yellow (4 of 12)对应的详细信息为: 123456789101112&#123; &quot;cluster_name&quot;: &quot;elasticsearch-cluster-centos&quot;, &quot;status&quot;: &quot;yellow&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 1, &quot;number_of_data_nodes&quot;: 1, &quot;active_primary_shards&quot;: 4, &quot;active_shards&quot;: 4, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 8&#125; 意味着所有的主分片(primary shards)启动并且运行了,集群已经可以成功的接受任意请求,但是副本分片(replica shards)还没有全部可用。事实上所有的8个副本分片现在是unassigned（未分配）状态,即它们还未被分配给节点,在同一个节点上保存相同的数据副本是没有必要的，如果这个节点故障了，那所有的数据副本也会丢失。现在我们的集群已经功能完备，但是依旧存在因硬件故障而导致的数据丢失的风险。 增加故障转移上面实例中的集群有单点故障的风险,没有数据冗余备份。我们可以扩展节点来保护数据不被丢失.只要第二个节点与第一个节点有相同的cluster.name(实例中为elasticsearch-cluster-centos)，它就能自动发现并加入第一个节点的集群。 如果没有，检查日志找出哪里出了问题。这可能是网络广播被禁用，或者防火墙阻止了节点通信。 当我们启动第二个节点之后:集群中的分片结构图如下: 虽然,已经有4个副本分片被分陪到es-node2节点上来了，但是按照我们定义的副本分片的值为2, 还有4个分片处于未分片状态,此时对于我们设定的参数来说,集群的健康值还是所有主分片可用，但不是所有复制分片都可用. 对应的集群健康状况: cluster health: yellow (8 of 12) 对应的详细信息为:12345678910111213&#123; &quot;cluster_name&quot;: &quot;elasticsearch-cluster-centos&quot;, &quot;status&quot;: &quot;yellow&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 4, &quot;active_shards&quot;: 8, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 4 &#125; 所以我们还需要一个节点来分片这些副本分片,使集群达到高可用,再增加集群节点: 当我们启动第三个节点之后,整个集群上的分片都进行了有效分配,从图中可以看出.es-node1为这个集群生态中选举出来的主(master),es-node2和es-node3为集群生态中的slave(从). 这样,一些新的被索引的文档将首先被存储在主分片中，然后平行复制到关联的复制节点上。这可以确保我们的数据在主节点和复制节点上都可以被检索。 此时集群的健康状态如下： cluster health: green (12 of 12)对应的详细信息为： 12345678910111213&#123; &quot;cluster_name&quot;: &quot;elasticsearch-cluster-centos&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 3, &quot;number_of_data_nodes&quot;: 3, &quot;active_primary_shards&quot;: 4, &quot;active_shards&quot;: 12, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0 &#125; 下图为,节点es-node3加入时,分片分配过程中截取的临时图. 模拟节点宕机,集群主从重新选举上图中我们的主节点为es-node1,如果主节点宕掉后,会怎样呢. 如图:主节点对应的进程号7421,干掉它，此时es集群生态发生了如下变化,如图: es-node3被选举为主节点,es-node2为从节点,主分片与副本分片也变化了,主分片放置在了es-node2上,副本分片放置到了es-node3上,因为分片没有完全被分配,所以集群的健康状态变为yellow(所有主分片可用，但不是所有复制分片都可用),然后我们重启es-node1节点. 如图,重启后健康状态恢复到green,但是集群主从变化了,且主分片的位置也变化了. 模拟扩展节点 实例2中我们的集群已经达到高可用状态,对应的索引分片如图.此时我们想要扩展集群继续增加节点时,我们的分片会怎样呢,接下来我们再增加一个扩展节点es-node4. 如图:扩容后,可以看到片进行了重新分片,节点es-node1和es-node3上分别持有主分片。es-node2,es-node3,es-node4持有副本分片，由于笔者模拟过程中有主节点宕机操作, 所以从图中可以看出,新的生态集群中es-node4为主节点.对应的各个集群存储中包含的片分布信息如下: 这种状态下的片也是完全分配，green(所有主要和复制的分片都可用). 动态缩小或者扩容副本片数量副本节点的数量可以在运行中的集群中动态的变更，这允许我们可以根据需求扩大或者缩小规模。 比如我们执行一次缩小规模操作: 12345678PUT /dobbyindex/_settings&#123; &quot;number_of_replicas&quot; : 1&#125;执行结果返回:&#123; &quot;acknowledged&quot;: true&#125; 这时,我们看到片的信息分又重新做了调整: 主分片分布在节点es-node1,es-node3,es-node4上.从分片分布在es-node2,es-node3,es-node4上.","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"集群","slug":"集群","permalink":"http://pzhen.github.io/tags/集群/"}]},{"title":"Es – 倒排索引","slug":"Elasticsearch-–-倒排索引","date":"2017-07-20T08:38:47.000Z","updated":"2017-07-20T09:27:32.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-倒排索引/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-倒排索引/","excerpt":"","text":"Lucene 简介Lucene是Apache软件基金会中一个开放源代码的全文搜索引擎工具包，是一个全文搜索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文搜索引擎。Lucene最初是由Doug Cutting所撰写的，是一位资深全文索引/搜索专家，曾经是V-Twin搜索引擎的主要开发者，后来在Excite担任高级系统架构设计师，目前从事于一些Internet底层架构的研究。 Lucene 采用倒排索引倒排索引源于实际应用中需要根据属性的值来查找记录。 这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引（inverted index）。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件（inverted file）。 Lucene 如何构建倒排索引1.获取关键词由于倒排序是根据关键字索引来定位记录的，所以要先获取关键词。比如一篇文章，也就是一串字符串，要获取所有的分词（关键字），如果是英文字符串也就是所有单词，中文则依赖中文分词器来获取所有词语，然而不管英文还是中文有些词是无意义的比如“is”，“in”，“的”等等过滤掉，标点符号过滤掉，大小写统一，等等经过一系列的过滤筛选后得到分词，也就是我们的关键字。 例子： 假设有两篇文章1和文章2： 文章1的内容为：Tom lives in Guangzhou，I live in Guangzhou too.文章2的内容为：He once lived in Shanghai. 在Lucene中以上措施由Analyzer类完成分词处理，结果如下： 文章1的所有关键词为：[tom][live][guangzhou][i][live][guangzhou]文章2的所有关键词为：[he][live][shanghai] 2.建立倒排索引有了关键词后，我们就可以建立倒排索引了。上面的对应关系是：“文章号”对“文章中所有关键词”。倒排索引把这个关系倒过来，变成：“关键词”对“拥有该关键词的所有文章号”。 通常仅知道关键词在哪些文章中出现还不够，我们还需要知道关键词在文章中出现的次数和位置，加上位置与出现次数后如下： 以上就是Lucene索引结构中最核心的部分。我们注意到关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以用二元搜索算法快速定位关键词。 3.实现倒排索引实现时，Lucene将上面三列分别作为词典文件（Term Dictionary）、频率文件（frequencies）、位置文件（positions）保存。其中词典文件不仅保存了每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。Lucene中使用了field的概念，用于表达信息所在位置（如标题中、文章中、URL中），在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息，因为每个关键字一定属于一个或多个field。 4.压缩算法为了减小索引文件的大小，Lucene对索引还使用了压缩技术。首先，对词典文件中的关键词进行了压缩，关键词压缩为&lt;前缀长度，后缀&gt;，例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为。其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减少数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。 5.查询假设要查询单词“live”，Lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。词典通常非常小，因而，整个过程的时间是毫秒级的。而用普通的顺序匹配算法，不建索引，而是对所有文章的内容进行字符串匹配，这个过程将会相当缓慢，当文章数目很大时，时间往往是无法忍受的。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"倒排序","slug":"倒排序","permalink":"http://pzhen.github.io/tags/倒排序/"},{"name":"Lucene","slug":"Lucene","permalink":"http://pzhen.github.io/tags/Lucene/"}]},{"title":"Es – Ik 分词器","slug":"Elasticsearch-–-Ik-分词器","date":"2017-07-20T08:24:42.000Z","updated":"2017-07-20T09:28:21.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-Ik-分词器/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-Ik-分词器/","excerpt":"","text":"下载ik分词器包1https://github.com/medcl/elasticsearch-analysis-ik 解压1unzip elasticsearch-analysis-ik-master.zip 打包123cd elasticsearch-analysis-ik-mastermvn package 打包后的文件在elasticsearch-analysis-ik-master/target/目录下 集成到ES在elasticsearch-5.3.0/plugins下创建目录 ik1copy and unzip target/releases/elasticsearch-analysis-ik-5.3.0.zip to your-es-root/plugins/ik 然后删除 zip文件1rm -f elasticsearch-analysis-ik-5.3.0.zip 重启ES1./bin/elasticsearch 添加数据测试创建索引1curl -XPUT http://localhost:9200/user 创建mapping1234567891011121314151617181920curl -XPOST http://localhost:9200/user/fulltext/_mapping -d&apos;&#123; &quot;fulltext&quot;: &#123; &quot;_all&quot;: &#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot;, &quot;term_vector&quot;: &quot;no&quot;, &quot;store&quot;: &quot;false&quot; &#125;, &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot;, &quot;include_in_all&quot;: &quot;true&quot;, &quot;boost&quot;: 8 &#125; &#125; &#125;&#125;&apos; 我的理解就是solr中的分词器 的 fieldType。 添加文档123456789101112curl -XPOST http://localhost:9200/user/fulltext/1 -d&apos;&#123;&quot;content&quot;:&quot;美国留给伊拉克的是个烂摊子吗&quot;&#125;&apos;curl -XPOST http://localhost:9200/user/fulltext/2 -d&apos;&#123;&quot;content&quot;:&quot;公安部：各地校车将享最高路权&quot;&#125;&apos;curl -XPOST http://localhost:9200/user/fulltext/3 -d&apos;&#123;&quot;content&quot;:&quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot;&#125;&apos;curl -XPOST http://localhost:9200/user/fulltext/4 -d&apos;&#123;&quot;content&quot;:&quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot;&#125;&apos; 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556curl -XPOST http://localhost:9200/user/fulltext/_search?pretty -d&apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;content&quot; : &quot;中国&quot; &#125;&#125;, &quot;highlight&quot; : &#123; &quot;pre_tags&quot; : [&quot;&lt;tag1&gt;&quot;, &quot;&lt;tag2&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/tag1&gt;&quot;, &quot;&lt;/tag2&gt;&quot;], &quot;fields&quot; : &#123; &quot;content&quot; : &#123;&#125; &#125; &#125;&#125;&apos;结果集&#123; &quot;took&quot; : 7, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 4.278213, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;user&quot;, &quot;_type&quot; : &quot;fulltext&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 4.278213, &quot;_source&quot; : &#123; &quot;content&quot; : &quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot; &#125;, &quot;highlight&quot; : &#123; &quot;content&quot; : [ &quot;&lt;tag1&gt;中国&lt;/tag1&gt;驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot; ] &#125; &#125;, &#123; &quot;_index&quot; : &quot;user&quot;, &quot;_type&quot; : &quot;fulltext&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 2.2110996, &quot;_source&quot; : &#123; &quot;content&quot; : &quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot; &#125;, &quot;highlight&quot; : &#123; &quot;content&quot; : [ &quot;中韩渔警冲突调查：韩警平均每天扣1艘&lt;tag1&gt;中国&lt;/tag1&gt;渔船&quot; ] &#125; &#125; ] &#125;&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Ik","slug":"Ik","permalink":"http://pzhen.github.io/tags/Ik/"}]},{"title":"Es – 核心概念","slug":"Elasticsearch-–-核心概念","date":"2017-07-20T08:07:51.000Z","updated":"2017-07-20T09:28:08.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-核心概念/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-核心概念/","excerpt":"","text":"接近实时（NRT）Elasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟（通常是1秒）。 集群（cluster）一个集群就是由一个或多个节点组织在一起，它们共同持有你整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群。在产品环境中显式地设定这个名字是一个好习惯，但是使用默认值来进行测试/开发也是不错的。 节点（node）一个节点是你集群中的一个服务器，作为集群的一部分，它存储你的数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。 一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。 在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。 索引（index）一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。 在一个集群中，如果你想，可以定义任意多的索引。 类型（type）在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可以为评论数据定义另一个类型。 文档（document）一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。 在一个index/type里面，只要你想，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须被索引/赋予一个索引的type。 分片和复制（shards &amp; replicas）一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。 为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。 分片之所以重要，主要有两方面的原因： – 允许你水平分割/扩展你的内容容量– 允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，有两个主要原因：– 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。– 扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行 总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。 默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。 下面附上一张关于索引，类型，文档的三者关系图，便于很好的理解： 集群的架构简图：","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"}]},{"title":"Es – 安装","slug":"Elasticsearch-–-安装","date":"2017-07-20T07:54:38.000Z","updated":"2017-07-20T09:28:00.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-安装/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-安装/","excerpt":"","text":"由于高版本提高了安全级别，不能采用root账户启动. 下载下载地址：https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.3.0.zip 解压后执行1./bin/elasticsearch 错误处理错误提示123456Exception in thread &quot;main&quot; java.lang.RuntimeException: don&apos;t run elasticsearch as root. at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:93) at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:144) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:285) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)Refer to the log for complete error details. 解决错误因为版本的问题，最新的版本安全级别提高了，不允许采用root帐号启动，所以我们要添加一个用户。 12345678910111213#添加一个用户：elasticsearch$useradd elasticsearch#给用户elasticsearch设置密码，连续输入2次$passwd elasticsearch#创建一个用户组 esgroupadd es#分配 elasticsearch 到 es 组usermod -G elasticsearch es#这里注意下，如果提示用户“es”不存在，那么是因为服务器版本问题，你可以换成 usermod -G es elasticsearch ,也就是用户和用户组对调一下使用。#在elasticsearch 根目录下，给定用户权限。-R表示逐级（N层目录） ， * 表示 任何文件chown -R elasticsearch.es *#切换到elasticsearch用户su elasticsearch 如果不按上面的给用户 elasticsearch 分配权限目录。那么会报下面的错。 123456789101112131415161718192021java.io.FileNotFoundException: /home/es/elasticsearch-2.2.0/logs/elasticsearch.log (Permission denied) at java.io.FileOutputStream.open(Native Method) at java.io.FileOutputStream.(FileOutputStream.java:221) at java.io.FileOutputStream.(FileOutputStream.java:142) at org.apache.log4j.FileAppender.setFile(FileAppender.java:294) at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165) at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:223) at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307) at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172) at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104) at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842) at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768) at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648) at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514) at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440) at org.elasticsearch.common.logging.log4j.LogConfigurator.configure(LogConfigurator.java:128) at org.elasticsearch.bootstrap.Bootstrap.setupLogging(Bootstrap.java:204) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:258) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)log4j:ERROR Either File or DatePattern options are not set for appender [file].log4j:ERROR setFile(null,true) call failed. 修改配置文件12345678$ vi config/elasticsearch.yml#cluster namecluster.name: sojson-application#节点名称node.name: node-1#绑定IP和端口network.host: 123.88.88.88http.port: 9200 后台运行1./bin/elasticsearch -d 查找进程1ps -ef | grep elasticsearch","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"}]},{"title":"Vim colorschemes","slug":"Vim-colorschemes","date":"2017-07-20T06:52:07.000Z","updated":"2017-07-20T06:54:25.000Z","comments":true,"path":"2017/07/20/Vim-colorschemes/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Vim-colorschemes/","excerpt":"","text":"最近给vim换了个主题?，里面有丰富的主题，也可以去web页面去定制。给分享下： 12官方地址：http://bytefluent.com/vivify/GitHub：https://github.com/flazz/vim-colorschemes 我的设置是1colorscheme murphy 希望大家喜欢。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Vim","slug":"Linux/Vim","permalink":"http://pzhen.github.io/categories/Linux/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"http://pzhen.github.io/tags/Vim/"},{"name":"colorschemes","slug":"colorschemes","permalink":"http://pzhen.github.io/tags/colorschemes/"}]},{"title":"Iterm2 配色主题","slug":"Iterm2-配色主题","date":"2017-07-20T03:29:58.000Z","updated":"2017-07-20T03:35:26.000Z","comments":true,"path":"2017/07/20/Iterm2-配色主题/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Iterm2-配色主题/","excerpt":"","text":"下载请到 https://github.com/mbadolato/iTerm2-Color-Schemes 下载。 1git clone https://github.com/mbadolato/iTerm2-Color-Schemes.git 安装To install: Launch iTerm 2. Get the latest version at iterm2.com Type CMD+i (⌘+i) Navigate to Colors tab Click on Color Presets Click on Import Select the .itermcolors file(s) of the scheme(s) you’d like to use Click on Color Presets and choose a color scheme","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Iterm2","slug":"Iterm2","permalink":"http://pzhen.github.io/tags/Iterm2/"},{"name":"Mac","slug":"Mac","permalink":"http://pzhen.github.io/tags/Mac/"}]},{"title":"Python 中文编码问题","slug":"Python-中文编码问题","date":"2017-07-20T03:10:21.000Z","updated":"2017-07-20T03:23:13.000Z","comments":true,"path":"2017/07/20/Python-中文编码问题/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Python-中文编码问题/","excerpt":"","text":"文件编码Python中默认的编码格式是 ASCII 格式，在没修改编码格式时无法正确打印汉字，所以在读取中文时会报错。 解决方法为只要在文件开头加入 # -- coding: UTF-8 -- 或者 #coding=utf-8 就行了。 123#!/usr/bin/python# -*- coding: UTF-8 -*-print &quot;你好，世界&quot;; 所以如果大家在学习过程中，代码中包含中文，就需要在头部指定编码。 注意：Python3.X 源码文件默认使用utf-8编码，所以可以正常解析中文，无需指定 UTF-8 编码。 如果你使用编辑器，同时需要设置好编辑器的编码，如 Pycharm 设置步骤： 1.进入 file &gt; Settings，在输入框搜索 encoding。 2.找到 Editor &gt; File encodings，将 IDE Encoding 和 Project Encoding 设置为utf-8。 编码之间的转换例如 类Unix系统上编写的python，如果放到windows下面执行，比如输出的信息包含中文，就需要转换了，不管是 gb2312 转 utf8 还是 utf8 转 gb2312 都需要现将字符串转换成Unicode的编码，然后再转换成正确的编码例如：1print &quot;2.结算表格读取完成&quot;.decode(&apos;utf-8&apos;).encode(&apos;gb2312&apos;) 将输出的提示语utf8转成gb2312。 print list 中文如果查看print list 的时候里面中文也显示正确，方便调试可这样：1import uniout 引入该包 就可以显示list中的中文了。","categories":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/tags/Python/"}]},{"title":"Php 一致性哈希","slug":"Php-实现一致性哈希包含虚拟节点","date":"2017-07-20T02:43:35.000Z","updated":"2017-07-21T06:14:28.000Z","comments":true,"path":"2017/07/20/Php-实现一致性哈希包含虚拟节点/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Php-实现一致性哈希包含虚拟节点/","excerpt":"","text":"之前看到Es的分片路由机制，想到了分布式的一致性哈希， 从无虚拟哈希环，到添加上虚拟哈希环。 下面是php的实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129&lt;?phpfunction myHash($str) &#123; $hash = 0; $s = md5($str); $seed = 5; $len = 32; for ($i = 0; $i &lt; $len; $i++) &#123; $hash = ($hash &lt;&lt; $seed) + $hash + ord($s&#123;$i&#125;); &#125; return $hash &amp; 0x7FFFFFFF;&#125;class ConsistentHash &#123; #每个物理节点生成虚拟节点个数 public $virtual_num = 300; // server列表 public $_server_list = array(); // 延迟排序，因为可能会执行多次addServer private $_layze_sorted = FALSE; #server物理节点 public function addServer($server) &#123; $hash = myHash($server); $this-&gt;_layze_sorted = FALSE; if (!isset($this-&gt;_server_list[$hash])) &#123; $this-&gt;_server_list[$hash] = $server; &#125; return $this; &#125; #server虚拟节点 public function addServerVir($server) &#123; for ($i = 1; $i &lt;= $this-&gt;virtual_num; $i++) &#123; $hash_key = myHash($server.\"#\".$i); if(!isset($this-&gt;_server_list[$hash_key])) &#123; $this-&gt;_server_list[$hash_key] = $server; &#125; &#125; return $this; &#125; public function find($key) &#123; // 排序 if (!$this-&gt;_layze_sorted) &#123; ksort($this-&gt;_server_list); $this-&gt;_layze_sorted = TRUE; &#125; #print_r($this-&gt;_server_list);exit(); $hash = myHash($key); $len = sizeof($this-&gt;_server_list); if ($len == 0) &#123; return FALSE; &#125; $keys = array_keys($this-&gt;_server_list); #server hash 值 $values = array_values($this-&gt;_server_list); #server 地址 if ($hash &lt;= $keys[0] || $hash &gt;= $keys[$len - 1]) &#123; return $values[0]; &#125; foreach ($keys as $key=&gt;$pos) &#123; $next_pos = NULL; if (isset($keys[$key + 1])) &#123; $next_pos = $keys[$key + 1]; &#125; if (is_null($next_pos)) &#123; return $values[$key]; &#125; // 区间判断 if ($hash &gt;= $pos &amp;&amp; $hash &lt;= $next_pos) &#123; return $values[$key]; &#125; &#125; &#125;&#125;$consisHash = new ConsistentHash();#物理节点hash环#$consisHash-&gt;addServer(\"server1\")-&gt;addServer(\"server2\")-&gt;addServer(\"server3\")-&gt;addServer(\"server4\");#带虚拟节点的hash环$consisHash-&gt;addServerVir(\"server1\")-&gt;addServerVir(\"server2\")-&gt;addServerVir(\"server3\")-&gt;addServerVir(\"server4\");$total_server1_num = $total_server2_num = $total_server3_num = $total_server4_num = 0;for ($i=1; $i &lt;= 200000; $i++) &#123; # code... $key = uniqid(TRUE,TRUE); $server_name = $consisHash-&gt;find($key); if($server_name == \"server1\")&#123; $total_server1_num += 1; &#125; if($server_name == \"server2\")&#123; $total_server2_num += 1; &#125; if($server_name == \"server3\")&#123; $total_server3_num += 1; &#125; if($server_name == \"server4\")&#123; $total_server4_num += 1; &#125;&#125;echo \"server1 num :\" .$total_server1_num .\"\\n\";echo \"server2 num :\" .$total_server2_num .\"\\n\";echo \"server3 num :\" .$total_server3_num .\"\\n\";echo \"server4 num :\" .$total_server4_num .\"\\n\"; 参考资料 flexihash","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"一致性Hash","slug":"一致性Hash","permalink":"http://pzhen.github.io/tags/一致性Hash/"}]},{"title":"Php7 安装Redis扩展","slug":"Php7-安装Redis扩展","date":"2017-07-20T02:39:26.000Z","updated":"2017-07-20T09:32:00.000Z","comments":true,"path":"2017/07/20/Php7-安装Redis扩展/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Php7-安装Redis扩展/","excerpt":"","text":"12345678910111213141516171819下载 https://github.com/phpredis/phpredis/tree/php7解压 unzip phpredis-php7.zipphpize #用phpize生成configure配置文件./configure 配置make #编译make install #安装安装完成后将出现的安装路径添加到php.ini中:extension_dir = &quot;/usr/lib/php/20151012&quot;extension = redis.so重启服务器,查看phpinfo,是不是搞定.","categories":[{"name":"Redis","slug":"Redis","permalink":"http://pzhen.github.io/categories/Redis/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"Redis","slug":"Redis","permalink":"http://pzhen.github.io/tags/Redis/"}]},{"title":"Ubuntu安装jdk","slug":"Ubuntu安装jdk","date":"2017-07-20T02:32:47.000Z","updated":"2017-07-20T02:37:35.000Z","comments":true,"path":"2017/07/20/Ubuntu安装jdk/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Ubuntu安装jdk/","excerpt":"","text":"Ubuntu 下安装 jdk 1.解压1sudo tar zxvf ./jdk-7u45-linux-x64.tar.gz 2.环境变量12345vi ~/.bashrc 或者 ~/.zshrcexport JAVA_HOME=/opt/Java/jdk/jdk1.7 export CLASSPATH=$&#123;JAVA_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 3.立即生效1source ~/.bashrc","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Jdk","slug":"Linux/Jdk","permalink":"http://pzhen.github.io/categories/Linux/Jdk/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Jdk","slug":"Jdk","permalink":"http://pzhen.github.io/tags/Jdk/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://pzhen.github.io/tags/Ubuntu/"}]},{"title":"Mac 安装 zsh","slug":"Mac-安装-zsh","date":"2017-07-20T02:07:00.000Z","updated":"2017-07-20T02:12:59.000Z","comments":true,"path":"2017/07/20/Mac-安装-zsh/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Mac-安装-zsh/","excerpt":"","text":"目前常用的 Linux 系统和 OS X 系统的默认 Shell 都是 bash，但是真正强大的 Shell 是深藏不露的 zsh， 这货绝对是马车中的跑车，跑车中的飞行车，史称『终极 Shell』，但是由于配置过于复杂，所以初期无人问津，很多人跑过来看看 zsh 的配置指南，什么都不说转身就走了。直到有一天，国外有个穷极无聊的程序员开发出了一个能够让你快速上手的zsh项目，叫做「oh my zsh」，这玩意就像「X天叫你学会 C++」系列，可以让你神功速成，而且是真的。 地址：https://github.com/robbyrussell/oh-my-zsh","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://pzhen.github.io/tags/Mac/"},{"name":"Zsh","slug":"Zsh","permalink":"http://pzhen.github.io/tags/Zsh/"}]},{"title":"Linux下 SSH 登录脚本","slug":"Linux下-ssh-自动登录脚本","date":"2017-07-19T14:58:13.000Z","updated":"2017-07-20T09:33:37.000Z","comments":true,"path":"2017/07/19/Linux下-ssh-自动登录脚本/","link":"","permalink":"http://pzhen.github.io/2017/07/19/Linux下-ssh-自动登录脚本/","excerpt":"","text":"最近由于频繁操作vps，发现每次输入密码太费劲，所以写了个自动登录shell脚本。 1.创建脚本 xxx.sh12345#!/usr/bin/expectset timeout 30spawn ssh -l root ip地址expect &quot;password:&quot;send &quot;密码\\r&quot; 2.将脚本目录加入环境变量export PATH=/Users/zhen/Documents/shell:$PATH这样一来在命令行随时可以调用脚本远程登录。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"http://pzhen.github.io/tags/SSH/"},{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"}]},{"title":"Vim 常用命令","slug":"Vim-常用命令","date":"2017-07-19T09:42:58.000Z","updated":"2017-07-19T14:29:39.000Z","comments":true,"path":"2017/07/19/Vim-常用命令/","link":"","permalink":"http://pzhen.github.io/2017/07/19/Vim-常用命令/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778----------------------------光标移动-------------------------h 向左移动一个字符j 向下移动一行k 向上移动一行l 向右移动一个字符 control f 向下翻一页control b 向上翻一页control d 向下翻半页control u 向上翻半页 + 非空格下一行- 非空格上一行 n + 空格 移动n个字符0 移动到当前行第一个字符处$ 移动到当前行最后一个字符处G 移动到最后一行nG 跳到n行gg 第一行 n 回车 向下n行?keyword 向上查找 配合 n N 来上下查找/keyword 向下查找 配合 n N 来上下查找 :n1,n2s/keyword1/keyword2/g 在n1到n2行之间，查找keyword1并且替换成keyword2:1,$s/keyword1/keyword2/g 同上只不过是从1-最后一行:n1,n2/keyword1/keyword2/gc 只不过要确认后才替换 -----------------------------粘贴复制------------------------x 向后删除一个字符X 向前删除一个字符nx 连续向后删除n个字符dd 删除当前行ndd 删除向下n行 d1G 删除光标之前所有dG 删除光标到最后d$ 删除光标到行末d0 删除光标行首 yy 复制当前航nyy 向下复制n行y1G 复制光标到行首yG 复制光标到最后一行y0 复制光标到行首y$ 复制光标到行末 p 光标下一行粘贴P 光标上一行粘贴 ---------------------------------插入------------------------i 光标位置插入I 当前行非空第一个字符处插入a 光标处下一个字符插入A 当前行最后一个字符插入o 下一行插入o 上一行插入 :w filename 保存到另一个文件:r filename 读取文件内容到当前 :! command 暂时离开vim 执行命令---------------------区块选择-------------------------------v 字符区块选择V 行区块选择y 复制区块d 删除区块contrl + v 范围区块区块选择下 按 = 键 自动排版，代码会自动排版--------------------多文件同时编辑--------------------------vim filename1 filename2:n 下一个文件:N 上一个文件:files 打开的文件列表-------------------分屏---------------------:sp filenamectrl + w 来切换光标","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Vim","slug":"Linux/Vim","permalink":"http://pzhen.github.io/categories/Linux/Vim/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Vim","slug":"Vim","permalink":"http://pzhen.github.io/tags/Vim/"}]},{"title":"Svn log shell","slug":"svn-log-shell","date":"2017-07-19T08:44:22.000Z","updated":"2017-07-19T14:51:31.000Z","comments":true,"path":"2017/07/19/svn-log-shell/","link":"","permalink":"http://pzhen.github.io/2017/07/19/svn-log-shell/","excerpt":"","text":"1.命令繁琐由于每次查看log需要输入好长的命令，在这里写成shell，方便许多。 1234567891011121314151617user_name=$1few_days_ago=$2if [ ! -n &quot;$user_name&quot; ]then user_name=&apos;xxxxxxxxxxxx&apos;fiif [ ! -n &quot;$few_days_ago&quot; ]then few_days_ago=30fistart_time=`date -v -&quot;$few_days_ago&quot;d +%Y-%m-%d`end_time=`date -v +1d +%Y-%m-%d`svn log -r &#123;$start_time&#125;:&#123;$end_time&#125; -v | sed -n &quot;/$user_name/,/--$/ p&quot; 2.使用方法:将shell加入环境变量，在项目里面: 1└─[$] &lt;&gt; svnlog.sh username days 3.默认参数如果不传参数默认脚本中username,30天的log。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"Svn","slug":"Svn","permalink":"http://pzhen.github.io/tags/Svn/"}]}]}