{"meta":{"title":"斑斓的梦","subtitle":"Zhen's Blog","description":"个人技术博客","author":"P.Zhen","url":"http://pzhen.github.io"},"pages":[{"title":"About","date":"2017-08-04T03:42:49.000Z","updated":"2017-08-04T03:42:49.000Z","comments":true,"path":"about/index.html","permalink":"http://pzhen.github.io/about/index.html","excerpt":"","text":"Hi，欢迎来到我的博客，作者是一名coder。 13年毕业，毕业后一直在我大帝都从事PHP开发工作。 性格还算开朗。 梦想嘛，成为一名后端架构师，虽然路比较远，但是万一实现了呢， O(∩_∩)O哈哈~ 爱好广泛，羽毛球、游泳、爬山、跑步、骑单车、旅游、读书、玩游戏…… 技术方面，还是比较能折腾，喜欢PHP，喜欢Python，也喜欢Golang。 新的起点，爱技术，爱生活，爱读书。“给自己一个机会，给自己一次改变”，在这里希望有些知识可以帮助到更多的人，希望能记录下生活的点滴。“就算路不坦荡，也要做自己的太阳”，希望自己可以走的更远，你我共勉。"},{"title":"Categories","date":"2017-07-21T06:36:21.000Z","updated":"2017-07-21T06:36:21.000Z","comments":true,"path":"categories/index.html","permalink":"http://pzhen.github.io/categories/index.html","excerpt":"","text":""},{"title":"好友","date":"2017-08-04T03:19:41.000Z","updated":"2017-08-04T03:19:41.000Z","comments":true,"path":"links/index.html","permalink":"http://pzhen.github.io/links/index.html","excerpt":"","text":"AirZilong的博客 - 然~，需要奋斗！ nanjishidu - do one thing and do it well 知者网 - 人人为我，我为人人。 斑斓的梦 – 爱技术，爱生活，爱读书 斑斓的梦(GitHub) – 爱技术，爱生活，爱读书"},{"title":"事迹","date":"2017-08-04T03:47:44.000Z","updated":"2017-08-04T03:47:44.000Z","comments":true,"path":"story/index.html","permalink":"http://pzhen.github.io/story/index.html","excerpt":"","text":"七月 2017 15日 数据迁移至GitHub，构建静态站点。http://pzhen.github.io 18日 由于国内访问速度太慢，借助七牛云。http://www.golangtab.com 五月 2017 3日 迁移代码仓库，托管于 阿里云。 15日 切换新域名:www.golangtab.com。 18日 改变数据库备份策略。 四月 2017 22日 前端页面改版升级。 26日 静态资源托管 七牛云，加速访问。 28日 申请新域名golangtab.com，网站更名 Golang+Tab 。 三月 2017 25日 斑斓的梦ぷ 正式上线，托管于 阿里云。"},{"title":"Tags","date":"2017-07-21T06:36:27.000Z","updated":"2017-07-21T06:36:27.000Z","comments":true,"path":"tags/index.html","permalink":"http://pzhen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Shell – Tail读取中间行","slug":"Shell-–-Tail读取中间行","date":"2017-08-03T07:43:26.000Z","updated":"2017-08-03T07:46:39.000Z","comments":true,"path":"2017/08/03/Shell-–-Tail读取中间行/","link":"","permalink":"http://pzhen.github.io/2017/08/03/Shell-–-Tail读取中间行/","excerpt":"linux 如何显示一个文件的某几行(中间几行)","text":"linux 如何显示一个文件的某几行(中间几行) 12345#从第3000行开始，显示1000行。即显示3000~3999行cat filename | tail -n +3000 | head -n 1000 # sed 5-10 行sed -n '5,10p' filename","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"Tail","slug":"Tail","permalink":"http://pzhen.github.io/tags/Tail/"}]},{"title":"Php 一逐行读取文件","slug":"Php-逐行读取文件","date":"2017-08-03T07:38:04.000Z","updated":"2017-08-03T07:39:39.000Z","comments":true,"path":"2017/08/03/Php-逐行读取文件/","link":"","permalink":"http://pzhen.github.io/2017/08/03/Php-逐行读取文件/","excerpt":"PHP逐行读取数据","text":"PHP逐行读取数据 1234567891011&lt;?php$file = fopen(\"Minot.txt\", \"r\") or exit(\"Unable to open file!\");//Output a line of the file until the end is reached//feof() check if file read end EOFwhile(!feof($file))&#123; //fgets() Read row by row echo fgets($file). \"&lt;br /&gt;\";&#125;fclose($file);?&gt;","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"读取文件","slug":"读取文件","permalink":"http://pzhen.github.io/tags/读取文件/"}]},{"title":"Python 验证日期格式","slug":"Python-验证日期格式","date":"2017-08-03T07:18:46.000Z","updated":"2017-08-03T07:20:55.000Z","comments":true,"path":"2017/08/03/Python-验证日期格式/","link":"","permalink":"http://pzhen.github.io/2017/08/03/Python-验证日期格式/","excerpt":"","text":"1234567import reprint re.search(r'\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;', 'xxxx1990-12-20xxxx').group(0)print re.search(r'\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;T\\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;', 'xxxx2005-06-04T18:37:11xxxx').group(0)print re.search(r'\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;T\\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125;', 'xxxx2005-06-04T18:37:11.111xxxx').group(0) pattern=re.compile(r'(\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;)((T\\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;|))((.\\d&#123;3&#125;)|)')print pattern.search('xxxx2005-06-04T18:37:11.111xxxx').group(0)","categories":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/tags/Python/"},{"name":"日期格式","slug":"日期格式","permalink":"http://pzhen.github.io/tags/日期格式/"}]},{"title":"Python Isinstance","slug":"Python-Isinstance","date":"2017-08-03T07:13:50.000Z","updated":"2017-08-03T07:15:27.000Z","comments":true,"path":"2017/08/03/Python-Isinstance/","link":"","permalink":"http://pzhen.github.io/2017/08/03/Python-Isinstance/","excerpt":"在Python中只需要使用内置的函数isinstance，使用起来非常简单","text":"在Python中只需要使用内置的函数isinstance，使用起来非常简单 12345678910class objA: pass A = objA() B = 'a','v' C = 'a string' print isinstance(A, objA) print isinstance(B, tuple) print isinstance(C, basestring)","categories":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/tags/Python/"},{"name":"Isinstance","slug":"Isinstance","permalink":"http://pzhen.github.io/tags/Isinstance/"}]},{"title":"Php 一浮点数精确运算","slug":"Php-浮点数精确运算","date":"2017-08-03T06:55:40.000Z","updated":"2017-08-03T07:20:04.000Z","comments":true,"path":"2017/08/03/Php-浮点数精确运算/","link":"","permalink":"http://pzhen.github.io/2017/08/03/Php-浮点数精确运算/","excerpt":"如果用php的+-*/计算浮点数的时候，可能会遇到一些计算结果错误的问题，所以基本上大部分语言都提供了精准计算的类库或函数库，比如php有BC高精确度函数库，下面我们介绍一下一些常用的BC高精确度函数使用。","text":"如果用php的+-*/计算浮点数的时候，可能会遇到一些计算结果错误的问题，所以基本上大部分语言都提供了精准计算的类库或函数库，比如php有BC高精确度函数库，下面我们介绍一下一些常用的BC高精确度函数使用。 bc是Binary Calculator的缩写。bc*函数的参数都是操作数加上一个可选的 [int scale]，比如string bcadd(string $left_operand, string $right_operand[, int $scale])，如果scale没有提供，就用bcscale的缺省值。这里大数直接用一个由0-9组成的string表示，计算结果返回的也是一个 string。bcadd — 将两个高精度数字相加bccomp — 比较两个高精度数字，返回-1, 0, 1bcdiv — 将两个高精度数字相除bcmod — 求高精度数字余数bcmul — 将两个高精度数字相乘bcpow — 求高精度数字乘方bcpowmod — 求高精度数字乘方求模，数论里非常常用bcscale — 配置默认小数点位数，相当于就是Linux bc中的”scale=”bcsqrt — 求高精度数字平方根bcsub — 将两个高精度数字相减 123$a = 0.1;$b = 0.7;var_dump(($a + $b) == 0.8); 打印出来的值居然为 boolean false这是为啥?PHP手册对于浮点数有以下警告信息:Warning浮点数精度显然简单的十进制分数如同 0.1 或 0.7 不能在不丢失一点点精度的情况下转换为内部二进制的格式。这就会造成混乱的结果：例如，floor((0.1+0.7)*10) 通常会返回 7 而不是预期中的 8，因为该结果内部的表示其实是类似 7.9999999999…。这和一个事实有关，那就是不可能精确的用有限位数表达某些十进制分数。例如，十进制的 1/3 变成了 0.3333333. . .。所以永远不要相信浮点数结果精确到了最后一位，也永远不要比较两个浮点数是否相等。如果确实需要更高的精度，应该使用任意精度数学函数或者 gmp 函数那么上面的算式我们应该改写为 123$a = 0.1;$b = 0.7;var_dump(bcadd($a,$b,2) == 0.8); 这样就能解决浮点数的计算问题了","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"浮点数","slug":"浮点数","permalink":"http://pzhen.github.io/tags/浮点数/"},{"name":"运算","slug":"运算","permalink":"http://pzhen.github.io/tags/运算/"},{"name":"精度","slug":"精度","permalink":"http://pzhen.github.io/tags/精度/"}]},{"title":"Php 一Ubuntu apt-get LAMP","slug":"Php-Ubuntu-apt-get-LAMP","date":"2017-08-02T02:21:39.000Z","updated":"2017-08-02T03:14:44.000Z","comments":true,"path":"2017/08/02/Php-Ubuntu-apt-get-LAMP/","link":"","permalink":"http://pzhen.github.io/2017/08/02/Php-Ubuntu-apt-get-LAMP/","excerpt":"安装过程第一步 安装Apache2sudo apt-get install apache2第二步 安装PHP模块sudo apt-get install php5第三步 安装Mysqlsudo apt-get install mysql-serversudo apt-get install mysql-client第四步 其他模块安装","text":"安装过程第一步 安装Apache2sudo apt-get install apache2第二步 安装PHP模块sudo apt-get install php5第三步 安装Mysqlsudo apt-get install mysql-serversudo apt-get install mysql-client第四步 其他模块安装sudo apt-get install libapache2-mod-php5sudo apt-get install libapache2-mod-auth-mysqlsudo apt-get install php5-mysqlsudo apt-get install php5-gd第五步 测试Apache是否正常工作打开浏览器，输入localhost，看看是否有It Works!网页展示。目录为/var/www第六步 修改权限/var/wwwsudo chomod 777 /var/www第七步 安装phpmyadminsudo apt-get install phpmyadmin安装过程中选择apache2，点击确定。下一步选择是要配置数据库，并输入密码。第八步 测试phpmyadmin 配置过程第一步 启用mod_rewrite模块sudo a2enmod rewrite重启Apache服务器：sudo/etc/init.d/apache2restart或者sudo service apache2 restart 第二步 设置Apache支持.htm .html .php第三步 测试php网页编辑mysql_test.php代码如下：&lt;?php$link = mysql_connect(“localhost”, “root”, “password”);if(!$link)die(‘Could not connect: ‘ . mysql_error());elseecho “Mysql 配置正确!”;mysql_close($link);?&gt;访问 http://localhost/mysql_test.php 显示’Mysql 配置正确‘就代表配置正确。第四步 第三步这里出现了乱码以后解决方法到此为止配置OK。","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://pzhen.github.io/tags/Ubuntu/"},{"name":"LAMP","slug":"LAMP","permalink":"http://pzhen.github.io/tags/LAMP/"}]},{"title":"Solr-Mmseg4j分词","slug":"Solr-Mmseg4j分词","date":"2017-08-01T07:30:25.000Z","updated":"2017-08-01T07:31:49.000Z","comments":true,"path":"2017/08/01/Solr-Mmseg4j分词/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Solr-Mmseg4j分词/","excerpt":"","text":"12345678910111213141516171819&lt;fieldtype name=\"textComplex\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt; &lt;analyzer&gt; &lt;tokenizer class=\"com.chenlb.mmseg4j.solr.MMSegTokenizerFactory\" mode=\"complex\" dicPath=\"/Users/zhen/opt/solr-5.5.3/server/solr/comic/conf/dic/\" /&gt; &lt;filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"/Users/zhen/opt/solr-5.5.3/server/solr/comic/conf/stopwords.txt\" /&gt; &lt;/analyzer&gt;&lt;/fieldtype&gt;&lt;!--&lt;fieldtype name=\"textMaxWord\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt; &lt;analyzer&gt; &lt;tokenizer class=\"com.chenlb.mmseg4j.solr.MMSegTokenizerFactory\" mode=\"max-word\" /&gt; &lt;/analyzer&gt;&lt;/fieldtype&gt;&lt;fieldtype name=\"textSimple\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt; &lt;analyzer&gt; &lt;tokenizer class=\"com.chenlb.mmseg4j.solr.MMSegTokenizerFactory\" mode=\"simple\" dicPath=\"n:/custom/path/to/my_dic\" /&gt; &lt;/analyzer&gt;&lt;/fieldtype&gt;--&gt;","categories":[{"name":"Solr","slug":"Solr","permalink":"http://pzhen.github.io/categories/Solr/"}],"tags":[{"name":"Solr","slug":"Solr","permalink":"http://pzhen.github.io/tags/Solr/"},{"name":"Mmseg4j","slug":"Mmseg4j","permalink":"http://pzhen.github.io/tags/Mmseg4j/"}]},{"title":"Html-漂亮的后台模板","slug":"Html-漂亮的后台模板","date":"2017-08-01T07:22:17.000Z","updated":"2017-08-01T07:23:49.000Z","comments":true,"path":"2017/08/01/Html-漂亮的后台模板/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Html-漂亮的后台模板/","excerpt":"","text":"分享一个后台模板地址，喜欢的可以自己克隆。 http://envato.stammtec.de/themeforest/melon/pages_user_profile.html","categories":[{"name":"Html","slug":"Html","permalink":"http://pzhen.github.io/categories/Html/"}],"tags":[{"name":"Html","slug":"Html","permalink":"http://pzhen.github.io/tags/Html/"},{"name":"Template","slug":"Template","permalink":"http://pzhen.github.io/tags/Template/"}]},{"title":"Tools-Vmware fusion 8.5 pro 注册码","slug":"Tools-Vmware-fusion-8-5-pro-注册码","date":"2017-08-01T07:19:33.000Z","updated":"2017-08-01T07:20:05.000Z","comments":true,"path":"2017/08/01/Tools-Vmware-fusion-8-5-pro-注册码/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Tools-Vmware-fusion-8-5-pro-注册码/","excerpt":"","text":"FY7N2-6RGD2-081XZ-UYWQC-ZPKCA","categories":[{"name":"Tools","slug":"Tools","permalink":"http://pzhen.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://pzhen.github.io/tags/Tools/"}]},{"title":"Tools-Win8.1专业版秘钥","slug":"Tools-Window8-1专业版本秘钥","date":"2017-08-01T07:17:27.000Z","updated":"2017-08-01T07:18:45.000Z","comments":true,"path":"2017/08/01/Tools-Window8-1专业版本秘钥/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Tools-Window8-1专业版本秘钥/","excerpt":"","text":"XHQ8N C3MCJ RQXB6 WCHYG C9WKB","categories":[{"name":"Tools","slug":"Tools","permalink":"http://pzhen.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://pzhen.github.io/tags/Tools/"}]},{"title":"Tools-XP注册码","slug":"Tools-XP注册码","date":"2017-08-01T07:14:25.000Z","updated":"2017-08-01T07:14:58.000Z","comments":true,"path":"2017/08/01/Tools-XP注册码/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Tools-XP注册码/","excerpt":"","text":"QC986-27D34-6M3TY-JJXP9-TBGMDCM3HY-26VYW-6JRYC-X66GX-JVY2DDP7CM-PD6MC-6BKXT-M8JJ6-RPXGJF4297-RCWJP-P482C-YY23Y-XH8W3HH7VV-6P3G9-82TWK-QKJJ3-MXR96HCQ9D-TVCWX-X9QRG-J4B2Y-GR2TTM6TF9-8XQ2M-YQK9F-7TBB2-XGG88DG8FV-B9TKY-FRT9J-6CRCC-XPQ4G","categories":[{"name":"Tools","slug":"Tools","permalink":"http://pzhen.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://pzhen.github.io/tags/Tools/"},{"name":"注册码","slug":"注册码","permalink":"http://pzhen.github.io/tags/注册码/"}]},{"title":"Funny-书生拿着书在打瞌睡","slug":"Funny-书生拿着书在打瞌睡","date":"2017-08-01T07:08:03.000Z","updated":"2017-08-01T07:09:22.000Z","comments":true,"path":"2017/08/01/Funny-书生拿着书在打瞌睡/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Funny-书生拿着书在打瞌睡/","excerpt":"书生拿着书在打瞌睡。欣赏他的人说，你瞧，他多用功，睡着了还拿着书。","text":"书生拿着书在打瞌睡。欣赏他的人说，你瞧，他多用功，睡着了还拿着书。不欣赏他的人说，你瞧，他多懒惰，一拿着书就睡着了。看的人不同了，书生就不是那个书生了。你爱他的时候，他的缺点都是优点，你不爱他了，他的优点也成了缺点。看的眼光不同了，他就不是他了。和一个人牵手的时候，就以为会是一生一世的相守。等到隔着太长的一段心路望回来，才惊讶地发现，虽然彼此都那么熟悉地活在彼此身边，却连相互述说的欲望都已经没有。是的，冷眼旁观着，彼此都在不知不觉中成了河川。而河川，永远都只会觉得是对方这座桥在走。 一则佛教故事。从前有个书生, 和未婚妻约好在某年某月某日结婚。到那一天，未婚妻却嫁给了别人。书生受此打击, 一病不起。这时, 路过一游方僧人，从怀里摸出一面镜子叫书生看……书生看到茫茫大海，一名遇害的女子一丝不挂地躺在海滩上。路过一人, 看一眼，摇摇头, 走了。又路过一人, 将衣服脱下,给女尸盖上, 走了。再路过一人,过去, 挖个坑, 小心翼翼把尸体掩埋了。僧人解释道, 那具海滩上的女尸，就是你未婚妻的前世。你是第二个路过的人，曾给过他一件衣服，她今生和你相恋, 只为还你一个情。但是她最终要报答一生一世的人, 是最后那个把她掩埋的人, 那人就是他现在的丈夫。书生大悟。 前世，究竟是谁埋了你？金岳霖找到了林徽因。他用一生的孤独来回报林徽因这位前世埋了他的人。徐志摩找到了谁？“我将于茫茫人海中访我唯一灵魂的伴侣，得之，我幸；不得，我命。如此而已。”这是他在追求陆小曼时说的话。他轻轻地从林徽因的身边走了，正如他轻轻地 来，他轻轻地挥手，没有带走林身边的一朵云彩。为了满足陆奢靡的生活，他频繁的往来于南北授课，在碧蓝的天空中，他把他34岁的生命回报给了前世埋他的陆小曼。人们从奈何桥上匆匆走过。孟婆说：“行路的人，喝碗孟婆汤解解渴。”口渴的人心急地喝了。于是，那个前世埋他们的人，在他们头脑中渐渐模糊了。他们开始惊惶地四处张望，妄图在茫茫 人海中寻找今生的爱人。“众里寻它千百度，蓦然回首，那人却在灯火阑珊处。”其实，你携起他的手时，就是前世残存的记忆在提醒你了，前世埋你的人，就是你 身边与你相濡以沫的爱人啊。 欣赏那个打瞌睡的书生吧。他真的很用功，你瞧，他睡着了还拿着书呢。月光下的大海，泛着粼粼的波。朋友说，思涵，和你的爱人去看看月光下的大海吧，在大海的最深处，也许就藏着你前生的记忆呢。我在屏幕前轻轻的笑了。三生石上的旧精魂，真的不是一个美丽的传说么？与前世埋过我的爱人，携手在银色的沙滩，那该是今生最完美的一种幸福了吧。我从奈何桥上走过，孟婆说：“行路的人，喝碗孟婆汤解解渴。”不，不不，我不喝，我宁愿在忘川河边忍受水淹火炙的磨折，我也一定要记得，前世，是谁埋的我…… 前世，究竟是谁埋了我……","categories":[{"name":"Funny","slug":"Funny","permalink":"http://pzhen.github.io/categories/Funny/"}],"tags":[{"name":"Funny","slug":"Funny","permalink":"http://pzhen.github.io/tags/Funny/"}]},{"title":"Arithmetic-一致性Hash","slug":"Arithmetic-一致性Hash","date":"2017-08-01T06:43:30.000Z","updated":"2017-08-01T06:52:13.000Z","comments":true,"path":"2017/08/01/Arithmetic-一致性Hash/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Arithmetic-一致性Hash/","excerpt":"","text":"一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义： 1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的： 环形Hash空间按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图 把数据通过一定的hash算法处理后映射到环上现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图： Hash(object1) = key1； Hash(object2) = key2； Hash(object3) = key3； Hash(object4) = key4； 将机器通过hash算法映射到环上在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下： Hash(NODE1) = KEY1; Hash(NODE2) = KEY2; Hash(NODE3) = KEY3; 通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。 机器的删除与添加普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。 1. 节点（机器）的删除以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图： 2. 节点（机器）的添加如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图： 通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。 平衡性根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。——“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下： 根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图：“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：Hash(“192.168.1.100”);引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：Hash(“192.168.1.100#1”); // NODE1-1Hash(“192.168.1.100#2”); // NODE1-2","categories":[{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://pzhen.github.io/categories/Arithmetic/"}],"tags":[{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://pzhen.github.io/tags/Arithmetic/"}]},{"title":"Funny-你笑了吗?","slug":"Funny-你笑了吗","date":"2017-08-01T06:17:15.000Z","updated":"2017-08-01T07:06:41.000Z","comments":true,"path":"2017/08/01/Funny-你笑了吗/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Funny-你笑了吗/","excerpt":"小漫画大道理","text":"小漫画大道理","categories":[{"name":"Funny","slug":"Funny","permalink":"http://pzhen.github.io/categories/Funny/"}],"tags":[{"name":"Funny","slug":"Funny","permalink":"http://pzhen.github.io/tags/Funny/"}]},{"title":"Funny-小漫画大道理","slug":"Funny-小漫画大道理","date":"2017-08-01T05:53:52.000Z","updated":"2017-08-01T06:04:24.000Z","comments":true,"path":"2017/08/01/Funny-小漫画大道理/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Funny-小漫画大道理/","excerpt":"小猫咪的哲理人生","text":"小猫咪的哲理人生","categories":[{"name":"Funny","slug":"Funny","permalink":"http://pzhen.github.io/categories/Funny/"}],"tags":[{"name":"Funny","slug":"Funny","permalink":"http://pzhen.github.io/tags/Funny/"}]},{"title":"Mem-内存管理原理","slug":"Memcached-内存管理原理","date":"2017-08-01T05:24:08.000Z","updated":"2017-08-01T05:34:19.000Z","comments":true,"path":"2017/08/01/Memcached-内存管理原理/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Memcached-内存管理原理/","excerpt":"","text":"内存管理中一个令人头痛的问题就是内存碎片管理。操作系统、虚拟机垃圾回收在这方面想了许多方法：压缩、复制。Memcached使用了一个非常简单的办法—固定空间分配。 Memcached 将内存空间分为一组slab，每个slab里面又包含一组chunk，同一个slab里面的每个chunk的大小是固定的，拥有相同大小的chunk的slab被组织在一起，叫做slab_class，如图所示。 存储数据时根据数据的size大小，寻找一个大于size的最小chunk将数据写入。这种内存管理方式避免了内存碎片的管理问题，内存的分配和释放都是以chunk为单位的。和其他缓存一样，memcached采用LRU算法释放最近最久未被访问的数据占用的空间，释放的chunk被标记为魏永，等待下一个合适大小数据的写入。 当然这种方式也会带来内存浪费的问题。数据只能存入一个比他大的chunk里，而一个chunk只能存一个数据，其他的空间被浪费了。如果启动参数配置不合理，浪费会更加惊人，发现没有缓存多少数据，内存空间就用尽了。","categories":[{"name":"Memcached","slug":"Memcached","permalink":"http://pzhen.github.io/categories/Memcached/"}],"tags":[{"name":"Memcached","slug":"Memcached","permalink":"http://pzhen.github.io/tags/Memcached/"},{"name":"原理","slug":"原理","permalink":"http://pzhen.github.io/tags/原理/"}]},{"title":"Mysql-CONCAT及GROUP_CONCAT","slug":"Mysql-CONCAT及GROUP-CONCAT","date":"2017-08-01T03:43:23.000Z","updated":"2017-08-01T03:46:47.000Z","comments":true,"path":"2017/08/01/Mysql-CONCAT及GROUP-CONCAT/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Mysql-CONCAT及GROUP-CONCAT/","excerpt":"","text":"一、CONCAT（）函数CONCAT（）函数用于将多个字符串连接成一个字符串。使用数据表Info作为示例，其中SELECT id,name FROM info LIMIT 1;的返回结果为+—-+——–+| id | name |+—-+——–+| 1 | BioCyc |+—-+——–+ 1、语法及使用特点：CONCAT(str1,str2,…)返回结果为连接参数产生的字符串。如有任何一个参数为NULL ，则返回值为 NULL。可以有一个或多个参数。 2、使用示例：SELECT CONCAT(id, ‘，’, name) AS con FROM info LIMIT 1;返回结果为+———-+| con |+———-+| 1,BioCyc |+———-+ SELECT CONCAT(‘My’, NULL, ‘QL’);返回结果为+————————–+| CONCAT(‘My’, NULL, ‘QL’) |+————————–+| NULL |+————————–+ 3、如何指定参数之间的分隔符使用函数CONCAT_WS（）。使用语法为：CONCAT_WS(separator,str1,str2,…)CONCAT_WS() 代表 CONCAT With Separator ，是CONCAT()的特殊形式。第一个参数是其它参数的分隔符。分隔符的位置放在要连接的两个字符串之间。分隔符可以是一个字符串，也可以是其它参数。如果分隔符为 NULL，则结果为 NULL。函数会忽略任何分隔符参数后的 NULL 值。但是CONCAT_WS()不会忽略任何空字符串。 (然而会忽略所有的 NULL）。 如SELECT CONCATWS(‘‘,id,name) AS con_ws FROM info LIMIT 1;返回结果为+———-+| con_ws |+———-+| 1_BioCyc |+———-+ SELECT CONCAT_WS(‘,’,’First name’,NULL,’Last Name’);返回结果为+———————————————-+| CONCAT_WS(‘,’,’First name’,NULL,’Last Name’) |+———————————————-+| First name,Last Name |+———————————————-+ 二、GROUP_CONCAT（）函数GROUP_CONCAT函数返回一个字符串结果，该结果由分组中的值连接组合而成。使用表info作为示例，其中语句SELECT locus,id,journal FROM info WHERE locus IN(‘AB086827’,’AF040764’);的返回结果为+———-+—-+————————–+| locus | id | journal |+———-+—-+————————–+| AB086827 | 1 | Unpublished || AB086827 | 2 | Submitted (20-JUN-2002) || AF040764 | 23 | Unpublished || AF040764 | 24 | Submitted (31-DEC-1997) |+———-+—-+————————–+ 1、使用语法及特点：GROUP_CONCAT([DISTINCT] expr [,expr …][ORDER BY {unsigned_integer | col_name | formula} [ASC | DESC] [,col …]][SEPARATOR str_val])在 MySQL 中，你可以得到表达式结合体的连结值。通过使用 DISTINCT 可以排除重复值。如果希望对结果中的值进行排序，可以使用 ORDER BY 子句。SEPARATOR 是一个字符串值，它被用于插入到结果值中。缺省为一个逗号 (“,”)，可以通过指定 SEPARATOR “” 完全地移除这个分隔符。可以通过变量 group_concat_max_len 设置一个最大的长度。在运行时执行的句法如下： SET [SESSION | GLOBAL] group_concat_max_len = unsigned_integer;如果最大长度被设置，结果值被剪切到这个最大长度。如果分组的字符过长，可以对系统参数进行设置：SET @@global.group_concat_max_len=40000; 2、使用示例：语句 SELECT locus,GROUP_CONCAT(id) FROM info WHERE locus IN(‘AB086827’,’AF040764’) GROUP BY locus; 的返回结果为+———-+——————+| locus | GROUP_CONCAT(id) |+———-+——————+| AB086827 | 1,2 || AF040764 | 23,24 |+———-+——————+ 语句 SELECT locus,GROUPCONCAT(distinct id ORDER BY id DESC SEPARATOR ‘‘) FROM info WHERE locus IN(‘AB086827’,’AF040764’) GROUP BY locus;的返回结果为+———-+———————————————————-+| locus | GROUPCONCAT(distinct id ORDER BY id DESC SEPARATOR ‘‘) |+———-+———————————————————-+| AB086827 | 2_1 || AF040764 | 24_23 |+———-+———————————————————-+ 语句SELECT locus,GROUP_CONCAT(concat_ws(‘, ‘,id,journal) ORDER BY id DESC SEPARATOR ‘. ‘) FROM info WHERE locus IN(‘AB086827’,’AF040764’) GROUP BY locus;的返回结果为+———-+————————————————————————–+| locus | GROUP_CONCAT(concat_ws(‘, ‘,id,journal) ORDER BY id DESC SEPARATOR ‘. ‘) |+———-+————————————————————————–+| AB086827 | 2, Submitted (20-JUN-2002). 1, Unpublished || AF040764 | 24, Submitted (31-DEC-1997) . 23, Unpublished |+———-+————————————————————————–+","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/tags/Mysql/"},{"name":"Concat","slug":"Concat","permalink":"http://pzhen.github.io/tags/Concat/"},{"name":"Group_concat","slug":"Group-concat","permalink":"http://pzhen.github.io/tags/Group-concat/"}]},{"title":"Mysql-Datediff()函数","slug":"Mysql-Datediff-函数","date":"2017-08-01T03:18:30.000Z","updated":"2017-08-01T03:21:17.000Z","comments":true,"path":"2017/08/01/Mysql-Datediff-函数/","link":"","permalink":"http://pzhen.github.io/2017/08/01/Mysql-Datediff-函数/","excerpt":"","text":"DATEDIFF() 函数返回两个日期之间的天数。 DATEDIFF(date1,date2) 事例：1234567SELECT *FROM con_contractWHERE datediff( FROM_UNIXTIME(remindtime, '%Y-%m-%d'),CURDATE() ) = &#123;$limit_time&#125; and state = 3 and archivestate &lt;&gt; 4 and archivestate &lt;&gt; 5\";","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/tags/Mysql/"},{"name":"Datediff","slug":"Datediff","permalink":"http://pzhen.github.io/tags/Datediff/"}]},{"title":"Mysql-Int类型","slug":"Mysql-Int类型","date":"2017-07-31T10:04:20.000Z","updated":"2017-08-01T02:11:17.000Z","comments":true,"path":"2017/07/31/Mysql-Int类型/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Mysql-Int类型/","excerpt":"几种整形数据类型的长度","text":"几种整形数据类型的长度 类型 占用空间(字节) 最小值(带符号的/无符号的) 最大值(带符号的/无符号的) ---------------------------------------------------------------------------------------------------- TINYINT 1 -128 127 0 255 ---------------------------------------------------------------------------------------------------- SMALLINT 2 -32768 32767 0 65535 ---------------------------------------------------------------------------------------------------- MEDIUMINT 3 -8388608 8388607 0 16777215 ---------------------------------------------------------------------------------------------------- int 4 -2147483648 2147483647 0 4294967295 ---------------------------------------------------------------------------------------------------- BIGINT 8 -9223372036854775808 9223372036854775807 0 18446744073709551615 ---------------------------------------------------------------------------------------------------- 注:1字节=8位","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/tags/Mysql/"},{"name":"Int","slug":"Int","permalink":"http://pzhen.github.io/tags/Int/"}]},{"title":"Mysql-Varchar类型","slug":"Mysql-Varchar类型","date":"2017-07-31T10:01:18.000Z","updated":"2017-07-31T10:06:51.000Z","comments":true,"path":"2017/07/31/Mysql-Varchar类型/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Mysql-Varchar类型/","excerpt":"","text":"1.varchar存储规则： 5.0版本以上，varchar(20)，指的是20字符，无论存放的是数字、字母还是UTF8汉字（每个汉字3字节），都可以存放20个. 上面测试过了如果超过20个字符mysql截取前20个插入 但是 最大大小是65532字节 也就是 varchar字节最大65535，utf8编码一个字符3个字节65535/3=21785。汉字不能超过21785. 2.关于varchar与set 类型中存储的字符串使用’,’隔开时 可以采用:SELECT * FROM 表名 WHERE FIND_IN_SET(‘要找的字符串’,字段);这种写法来找出; 最多可以有64个成员 枚举最多有65535种不同值","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/tags/Mysql/"},{"name":"Varchar","slug":"Varchar","permalink":"http://pzhen.github.io/tags/Varchar/"}]},{"title":"Mysql-蠕虫复制","slug":"Mysql-蠕虫复制","date":"2017-07-31T09:22:04.000Z","updated":"2017-07-31T09:23:19.000Z","comments":true,"path":"2017/07/31/Mysql-蠕虫复制/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Mysql-蠕虫复制/","excerpt":"","text":"1INSERT INTO `table` (`id`,`aa`,`bb`,`cc` ) SELECT '','aa内容','bb注意cc符号区别',`cc` FROM `table` (WHERE .....)","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/tags/Mysql/"}]},{"title":"Mysql-开启日志","slug":"Mysql-开启日志","date":"2017-07-31T09:18:58.000Z","updated":"2017-07-31T09:20:36.000Z","comments":true,"path":"2017/07/31/Mysql-开启日志/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Mysql-开启日志/","excerpt":"","text":"123456[mysqld]port=3306log=D:/mysql.loglog_slow_queries=C:/temp/mysql_slow.loglong_query_time=1 show binary logs; //查看binlog日志show binlog events in ‘mysql-bin.000181’; 查看日志是否开启1).可以通过Mysql配置文件my.cnf来确认（Mysql默认开启二进制日志记录）：Replication Master Server (default)binary logging is required for replicationlog-bin=mysql-bin刷新日志flush logs;查看当前日志位置show master status;查看当前所有日志show master logs;清空所有的bin-log日志reset master; 查看日志内容mysqlbinlog –no-defaults mysql-bin.00001;删除bin-logmysql&gt; purge binary logs to ‘ablelee.000003’;Query OK, 0 rows affected (0.16 sec)关闭 bin-log 日志找到配置文件my.cnf，对于linux，一般默认在/etc目录下，打开此文件，使用井号(#)注释掉如下两个配置项目即可。log-bin=mysql-binbinlog_format=mixed显示所有日志mysql&gt; show binary logs; //查看所有日志show binary logs;//查看正在使用的binlogshow master status; purge binary logs to ‘mysql-tb-bin.000005’;这个命令就是清理除mysql-tb-bin.000005以外的其他二进制日志； //查看binlog日志show binlog events in ‘mysql-bin.000181’;","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://pzhen.github.io/tags/Mysql/"},{"name":"日志","slug":"日志","permalink":"http://pzhen.github.io/tags/日志/"}]},{"title":"Php 一phpStorm快捷键","slug":"Php-phpStorm快捷键","date":"2017-07-31T08:35:26.000Z","updated":"2017-07-31T08:37:35.000Z","comments":true,"path":"2017/07/31/Php-phpStorm快捷键/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Php-phpStorm快捷键/","excerpt":"现在把一些使用技巧记录下来,免得到时候忘了再查. 来源于网络。","text":"现在把一些使用技巧记录下来,免得到时候忘了再查. 来源于网络。 1,从版本控制系统创建项目:CVS -&gt; Checkout from Version Control 2, 关联DOC文档:右键External Librariese -&gt; Configure PHP include paths 3, 去掉波浪线:settings -&gt; Editor -&gt; Colors &amp; Fonts -&gt; General -&gt; TYPO-&gt;Effects 4, 显示行号:settings -&gt; Editor-&gt;Appearance-&gt;Show line numbers 5,远程或本地同步文件:Tools -&gt; Deploments -&gt; Configuration 6, 去掉右上角浏览器图标:settings -&gt; tools -&gt; WebBrowsers 7, 添加VIM插件:settings-&gt;editor -&gt;plugins-&gt;browse repositories -&gt;搜索VIM 8,启动的时候不打开工程文件Settings-&gt;General去掉Reopen last project on startup. 9, 取消自动保存appearance -&gt; system settings -&gt; save file的两个选项 去掉 10, 将编辑的文件加星号标识:settings -&gt; editor -&gt; editor tabs -&gt; 勾选 mark modifed tabs… 11, 添加扩展名高亮显示:settings -&gt; editor -&gt; file types 1234567891011121314151617常用快捷键:control + option + l 将代码格式化command + shift + u 切换大小写command + shift + + / command + shift + - 折叠/展开所有区块command + e 列出最后打开的文件control + tab / control + shift + tab 切换打开的文件command + / 行注释ctrl + shift + / 块注释command + b 函数追踪,同command +单击command + alt + 左右箭头 操作动作前进/回退shift + command + r 按文件名搜索对应文件所在路径shift + command + t 按类名搜索对应文件所在路径shift + command + c 复制当前文件所在路径Command + Shift + O 打开文件Command + O 打开类alt + F1 定位编辑文件所在位置:alt + F12 打开命令行栏","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"PhpStorm","slug":"PhpStorm","permalink":"http://pzhen.github.io/tags/PhpStorm/"}]},{"title":"Shell – Wget 克隆网站","slug":"Shell-–-Wget-克隆网站到本地","date":"2017-07-31T08:14:22.000Z","updated":"2017-07-31T08:18:20.000Z","comments":true,"path":"2017/07/31/Shell-–-Wget-克隆网站到本地/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Shell-–-Wget-克隆网站到本地/","excerpt":"有时候觉得网上看到的漂亮的模板，想下载怎么办哈哈哈wget就搞定了。","text":"有时候觉得网上看到的漂亮的模板，想下载怎么办哈哈哈wget就搞定了。 1wget -k -p -nH -N http://www.baidu.com -k 把已下载文件中的所有链接都转换为本地引用，不在依赖原始或在线内容 -p 下载所有必要文件，确保离线可用，包括图片和样式表 -nH 禁止把文件下载到以主机名为前缀的文件夹中。 -N 启用文件的时间戳,以匹配来源的时间戳.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"Wget","slug":"Wget","permalink":"http://pzhen.github.io/tags/Wget/"}]},{"title":"Php 一Api通信规则","slug":"Php-Api通信规则","date":"2017-07-31T07:34:52.000Z","updated":"2017-07-31T07:53:37.000Z","comments":true,"path":"2017/07/31/Php-Api通信规则/","link":"","permalink":"http://pzhen.github.io/2017/07/31/Php-Api通信规则/","excerpt":"Api 通信中，可以采用非对称加密的方式，来提高安全性，也可以采用，下面的通信规则。 如果采用下面方式，可以将时间戳取前7位有效数字来加密这样每隔十几分钟MD5就一换，还能避开服务器时间不同步问题，也是不错的选择。","text":"Api 通信中，可以采用非对称加密的方式，来提高安全性，也可以采用，下面的通信规则。 如果采用下面方式，可以将时间戳取前7位有效数字来加密这样每隔十几分钟MD5就一换，还能避开服务器时间不同步问题，也是不错的选择。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** *生成THQS算法的信息查询串（Query string） */private function get_query_string($info) &#123; ksort($info); return $this-&gt;http_build_query($info);&#125;/** * 根据数组生成HTTP请求URL参数 * @param unknown_type $array */private function http_build_query($array) &#123; $query = ''; foreach ($array as $key =&gt; $value) &#123; $key = self::urlencode($key); $value = self::urlencode($value); $query .= \"$key=$value&amp;\"; &#125; if (strlen($query)) &#123; $query = substr($query, 0, -1); &#125; return $query;&#125;/** * *不要被转义了。 * @param $string */private function urlencode($string) &#123; $string = str_replace('*', '-tSl2nWmMsagD-gEr', $string); $string = urlencode($string); return str_replace('-tSl2nWmMsagD-gEr', '*', $string);&#125;/** * 生成THQS算法的hash值 * $salt = API Key 秘钥 */private function get_hashed_value($qs, $time, $salt) &#123; return strtoupper(md5($qs . \"&amp;time=$time&amp;salt=$salt\"));&#125;/* * return string*/private function ccXml()&#123; header('Content-Type:text/xml'); $str = ''; $str .= \"&lt;?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?&gt;\\n\"; $str .= \"&lt;result&gt;OK&lt;/result&gt;\"; return $str;&#125;","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"Api","slug":"Api","permalink":"http://pzhen.github.io/tags/Api/"}]},{"title":"Composer - 管理PHP依赖","slug":"Composer-管理PHP依赖关系","date":"2017-07-21T09:32:30.000Z","updated":"2017-07-22T08:30:34.000Z","comments":true,"path":"2017/07/21/Composer-管理PHP依赖关系/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Composer-管理PHP依赖关系/","excerpt":"简介现在软件规模越来越大，PHP项目的开发模式和许多年前已经有了很大变化。记得初学PHP那会儿，boblog是一个很好的例子，几乎可以代表 PHP项目的开发模式。当时PHP 5.x以上的版本刚开始流行，仍然有大量的生产环境使用PHP4.x。由于历史遗留的问题，OOP思想在PHP项目中还不是那么广泛流行。随着 PHP5.3的发布，PHP项目规模的扩大，在其他语言领域大展身手的OOP开发模式也在PHP中崭露头角。","text":"简介现在软件规模越来越大，PHP项目的开发模式和许多年前已经有了很大变化。记得初学PHP那会儿，boblog是一个很好的例子，几乎可以代表 PHP项目的开发模式。当时PHP 5.x以上的版本刚开始流行，仍然有大量的生产环境使用PHP4.x。由于历史遗留的问题，OOP思想在PHP项目中还不是那么广泛流行。随着 PHP5.3的发布，PHP项目规模的扩大，在其他语言领域大展身手的OOP开发模式也在PHP中崭露头角。大型项目不可能是从头开始的，使用社区已经提供的资源可以为项目带来很大的便利。然而各自为政的打包方式、依赖关系的处理，导致了很难将两个开源项 目集成到一起。虽然有pear这种PHP官方支持的包管理工具，但是依然没有很好的统一的依赖关系管理的办法。直到Composer的出现。 Composer的依赖关系管理风格，看上去更像Java的Maven。项目编译和打包、依赖关系的解决都可以很轻松的实现。再也不用费神去寻找或者更新第三方库，或者将他们集成到一起。这一切全部都可以交给Composer来完成。 例子首先来看一个类似于Helloworld的例子，让我们对Composer先有一个感性的认识吧。 如何在一个PHP项目中启用Composer，很简单，只需要在项目根目录中创建一个composer.json文件即可，它包含如下内容：12345&#123; &quot;require&quot;: &#123; &quot;monolog/monolog&quot;: &quot;1.2.*&quot; &#125;&#125; 这样我们便添加了对monolog这个库的引用。没错，就是这样简单。不过，你还需要使用composer来为你更新依赖包，打开你的Shell，切换到项目目录下执行：1composer install 这时，Composer便自动从互联网上更新指定依赖的库了。你会发现你的项目文件夹里面多了一个vendor文件夹，那就是依赖库包了。 接下来，你需要在你的系统的公共入口文件中引用自动加载器，以便自动加载类：1require 'vendor/autoload.php'; 安装上面的例子让大家对composer的使用有了一个大概的认识。下面将向大家介绍如何在PHP环境中安装composer。Unix/Linux/OSX环境 很幸运，利用Unix Like环境安装composer是一件很简单的事情。只需要一行命令：1curl -sS https://getcomposer.org/installer | php 此时会为你在当前工作目录安装composer.phar文件，使用php composer.phar即可运行。当然，你可能更想让composer变成像其他一样的Unix命令，很简单，只需要再加一步：1mv composer.phar /usr/local/bin/composer 注意，在权限受限的系统上，你可能需要使用sudo命令来提升至管理员账号执行。 这时，你就可以像例子里面那样使用composer了。Windows环境 Composer官方推荐使用安装包进行安装，据说下载Composer-Setup.exe这个即可用向导模式安装。 关于手工安装的方法，请参考http://getcomposer.org/doc/00-intro.md的介绍吧。 自动加载为了实现PHP类的随取随用，类的命名空间定义建议遵从一定的规则。这种规则可以是某一项目组约定的。不过为了使得类库统一，PHP-FIG项目指 定了一种PHP命名空间的规范PSR-0，被一些流行PHP项目采用。Composer支持这种规范的类库自动装载器，只需要向 composer.json文件中添加autoload节点即可：12345&#123; &quot;autoload&quot;: &#123; &quot;psr-0&quot;: &#123;&quot;Acme\\\\&quot;: &quot;src/&quot;&#125; &#125;&#125; 关于PSR-0规范，有这么几点重要的要求： 命名空间规范参考：\\()* 每个namespace需要一个顶层空间，即vendor name。用来指定在软件包级别上区别。 命名空间和PHP文件的路径是一一对应的，最终命名空间分隔符会被转为DIRECTORY_SEPARATOR 文件名必须为类名.php 关于这个规范，可以参考http://blog.mosil.biz/2012/08/psr-0-autoloading-standard/这篇文章。有关PSR-0的更多内容，可以参考他们的官方网站：https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-0.md 注意，修改了autoload后，要重新使用composer install。 注意：composer默认类库是使用PSR-0规范自动加载的。所以一般无需额外配置。 查找所需类库composer提供了一个类库的“商店”，在这里，你可以立即找到想要使用的开源类库包，然后把他们添加到你的项目中即可。传送门：https://packagist.org/ 打包自己的类库将自己的类库贡献给大家，首先需要为自己的类库设置打包信息（要首先保证自己的类库是利用composer管理的）。在composer.json文件中设置：1234567&#123; &quot;name&quot;: &quot;your-vendor-name/package-name&quot;, &quot;require&quot;: &#123; &quot;php&quot;: &quot;&gt;=5.3.0&quot;, &quot;another-vendor/package&quot;: &quot;1.*&quot; &#125;&#125; 然后就可以前去https://packagist.org/提交你的类库了。 参考资料 快速入门 文档 包列表","categories":[{"name":"Composer","slug":"Composer","permalink":"http://pzhen.github.io/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://pzhen.github.io/tags/Composer/"},{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"}]},{"title":"Shell – 正则表达式","slug":"Shell-–-正则表达式","date":"2017-07-21T09:00:23.000Z","updated":"2017-07-21T09:02:57.000Z","comments":true,"path":"2017/07/21/Shell-–-正则表达式/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Shell-–-正则表达式/","excerpt":"","text":"正则表达式的分类 基本的正则表达式（Basic Regular Expression 又叫Basic RegEx 简称BREs） 扩展的正则表达式（Extended Regular Expression 又叫Extended RegEx 简称EREs） Perl的正则表达式（Perl Regular Expression 又叫Perl RegEx 简称PREs） 基本组成部分正则表达式的基本组成部分。 POSIX字符类POSIX字符类是一个形如[:…:]的特殊元序列（meta sequence），他可以用于匹配特定的字符范围。 元字符元字符（meta character）是一种Perl风格的正则表达式，只有一部分文本处理工具支持它，并不是所有的文本处理工具都支持。 文章来源：http://man.linuxde.net/docs/shell_regex.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"正则","slug":"正则","permalink":"http://pzhen.github.io/tags/正则/"}]},{"title":"Git – 操作配置别名","slug":"Git-–-操作配置别名","date":"2017-07-21T08:40:57.000Z","updated":"2017-07-21T08:43:05.000Z","comments":true,"path":"2017/07/21/Git-–-操作配置别名/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Git-–-操作配置别名/","excerpt":"","text":"有没有经常敲错命令？比如Git status？status这个单词真心不好记。 如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。 我们只需要敲一行命令，告诉Git，以后st就表示status：1$ git config --global alias.st status 好了，现在敲git st看看效果。 当然还有别的命令可以简写，很多人都用co表示checkout，ci表示commit，br表示branch：123$ git config --global alias.co checkout$ git config --global alias.ci commit$ git config --global alias.br branch 以后提交就可以简写成：1$ git ci -m &quot;bala bala bala...&quot; –global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。 在撤销修改一节中，我们知道，命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名：1$ git config --global alias.unstage &apos;reset HEAD&apos; 当你敲入命令：1$ git unstage test.py 实际上Git执行的是：1$ git reset HEAD test.py 配置一个git last，让其显示最后一次提交信息：1$ git config --global alias.last &apos;log -1&apos; 这样，用git last就能显示最近一次的提交：1234567$ git lastcommit adca45d317e6d8a4b23f9811c3d7b7f0f180bfe2Merge: bd6ae48 291bea8Author: Michael Liao &lt;askxuefeng@gmail.com&gt;Date: Thu Aug 22 22:49:22 2013 +0800merge &amp; fix hello.py","categories":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/tags/Git/"},{"name":"别名","slug":"别名","permalink":"http://pzhen.github.io/tags/别名/"}]},{"title":"Shell – Grep 常见用法","slug":"Shell-–-Grep常见用法","date":"2017-07-21T08:36:51.000Z","updated":"2017-07-21T08:59:24.000Z","comments":true,"path":"2017/07/21/Shell-–-Grep常见用法/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Shell-–-Grep常见用法/","excerpt":"","text":"是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。我经常用来查找字符串比如： 1grep -rn \"字符串\" . 递归查找当前目录下所有文件中 “字符串” 并且所在标出所在行。 下面来看看具体参数：12345678grep [-acinv] [--color=auto] '搜寻字符串' filename 选项参数:-a :将 binary 档案以 text 档案方式搜寻数据-c :计算找刡 '搜寻字符串' 次数-i :忽略大小写-n :输出行号-v :反向选择，亦即显示出没有 '搜寻字符串' 内容癿那一行! --color=auto :可以将找刡癿关键词部分加上颜色癿显示!-A :后面可加数字，为 after 癿意思，除了列出该行外，后续的 n 行也列出; -B :后面可加数字，为 befer 癿意思，除了列出该行外，前面的 n 行也列出; grep 只支持基础正则表示法，若要延伸型正则，则要用egrep或者 grep -E。 基础正则表示法总结如下： 123456789^word：查找字符串(word)在行首 grep -n '^word' filenameword$: 查找字符串(word)在行末 grep -n 'word$' filename. : 任意字符\\ : 转译*：前面字符 0 到 任意多个[] : 字符集合[n1-n2] : 范围 如[0-9][^]: 字符取反，就是不能是里面的字符\\&#123;n,m\\&#125;: 出现n到m次 延伸正则表示总结如下： 12345+ ：一个或者一个以上？ ：零个或者一个| ： 或() : 群组 egrep -n 'g(la|oo)d' filename 找出 glad 或者 good 两个字符串()+: 群组出现一次或者多次 grep 还有很多高级用法，请感兴趣的自己去补给，我只列出了基础的常见的用法。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Grep","slug":"Grep","permalink":"http://pzhen.github.io/tags/Grep/"},{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"}]},{"title":"Git – 集中式与分布式","slug":"Git-–-集中式与分布式-版本控制系统区别","date":"2017-07-21T08:36:51.000Z","updated":"2017-07-21T08:48:24.000Z","comments":true,"path":"2017/07/21/Git-–-集中式与分布式-版本控制系统区别/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Git-–-集中式与分布式-版本控制系统区别/","excerpt":"","text":"Git – 集中式与分布式 版本控制系统区别Linus一直痛恨的CVS及SVN都是集中式的版本控制系统，而Git是分布式版本控制系统，集中式和分布式版本控制系统有什么区别呢？ 先说集中式版本控制系统，版本库是集中存放在中央服务器的，而大家工作的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始工作，工作完成，再把自己的修订推送给中央服务器。这类系统，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 那分布式版本控制系统与集中式版本控制系统有何不同呢？首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 在实际使用分布式版本控制系统的时候，其实很少在两人之间的电脑上推送版本库的修改，因为可能你们俩不在一个局域网内，两台电脑互相访问不了，也可能今天你的同事病了，他的电脑压根没有开机。因此，分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分别和不同工作小组的人相互协作。你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以前的集中式系统中是无法实现的。","categories":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/tags/Git/"},{"name":"集中式管理","slug":"集中式管理","permalink":"http://pzhen.github.io/tags/集中式管理/"},{"name":"分布式管理","slug":"分布式管理","permalink":"http://pzhen.github.io/tags/分布式管理/"}]},{"title":"Git – 全局与局部项目配置","slug":"Git-–-全局配置与局部项目配置","date":"2017-07-21T08:34:37.000Z","updated":"2017-07-21T09:51:41.000Z","comments":true,"path":"2017/07/21/Git-–-全局配置与局部项目配置/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Git-–-全局配置与局部项目配置/","excerpt":"","text":"Git全局配置的文件1cat ~/.gitconfig 上面就是全局配置文件位置。 git config –global &lt;配置名称&gt; &lt;配置的值&gt; 例如： $ git config –global user.name “用户名”$ git config –global user.email “邮箱” Git局部项目的配置文件你可以在项目中使用git config 命令不带 –global 选项来设置. 这会在你当前的项目目录下创建 .git/config，从而使用针对当前项目的配置。","categories":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/tags/Git/"}]},{"title":"Git – 基本工作流程","slug":"Git-–-基本工作流程","date":"2017-07-21T08:30:48.000Z","updated":"2017-07-21T08:52:15.000Z","comments":true,"path":"2017/07/21/Git-–-基本工作流程/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Git-–-基本工作流程/","excerpt":"","text":"git的基本流程如下： 首先获取项目为了得一个项目的拷贝(copy),我们需要知道这个项目仓库的地址(Git URL). Git能在许多协议下使用，所以Git URL可能以ssh://, http(s)://, git://. 有些仓库可以通过不只一种协议来访问。 例如ssh方式获取远程你在阿里云下的项目：git clone git@code.aliyun.com:username/xxxx(项目).git 另一种方式是还没有仓库，我们要把当前文件夹设为项目仓库 ：git init 在当前目录下就会有 .git 的文件夹了。 修改项目 创建或修改文件 使用git add命令添加新创建或修改的文件到本地的缓存区（Index） 使用git commit命令提交到本地代码库 （可选，有的时候并没有可以同步的远端代码库）使用git push命令将本地代码库同步到远端代码库","categories":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://pzhen.github.io/tags/Git/"}]},{"title":"Es – 安装插件","slug":"Elasticsearch-–-安装插件","date":"2017-07-21T08:23:35.000Z","updated":"2017-07-21T08:29:16.000Z","comments":true,"path":"2017/07/21/Elasticsearch-–-安装插件/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Elasticsearch-–-安装插件/","excerpt":"","text":"由于Elasticsearch-head 插件不支持5.3.0，比较费事，装个低版本的，安装个插件。 来看下 2.3.0 插件安装123./plugin install mobz/elasticsearch-headhttp://localhost:9200/_plugin/head 安装 bigdesk 集群管理插件。 bigdesk是elasticsearch的一个集群监控工具，可以通过它来查看es集群的各种状态，如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。项目git地址： https://github.com/lukas-vlcek/bigdesk。和head一样，它也是个独立的网页程序，使用方式和head一样。 1.下载bigdesk插件，bigdesk-master.zip。 2.复制到 es plugins 插件目录下1cp bigdesk-master.zip elasticsearch-2.3.0/plugins 3.解压 删除123unzip bigdesk-master.zip rm -rf bigdesk-master.zip 4.创建 _site 文件夹12cd bigdesk-mastermkdir _site 将 bigdesk-master 下刚刚解压的文件移动到 _site 下面。 4.创建 plugin-descriptor.properties 文件 添加一下内容： 1234description=bigdeskversion=bigdeskname=bigdesksite=true 5.修改js文件。 定位到plugins/bigdesk/_site/js/store目录，打开BigdeskStore.js，定位到142行 把 major ==1 改成 major &gt;=1，然后保存 6.搞定，浏览器查看1http://localhost:9200/_plugin/bigdesk-master/#nodes 最后附上我的目录结构：","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Ik","slug":"Ik","permalink":"http://pzhen.github.io/tags/Ik/"},{"name":"插件","slug":"插件","permalink":"http://pzhen.github.io/tags/插件/"}]},{"title":"Es - 单机多节点集群","slug":"Elasticsearch-–-单机多节点集群","date":"2017-07-21T08:11:43.000Z","updated":"2017-07-21T08:25:17.000Z","comments":true,"path":"2017/07/21/Elasticsearch-–-单机多节点集群/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Elasticsearch-–-单机多节点集群/","excerpt":"","text":"采用版本1.物理机 Mac 2.Elasticsearch 2.3.0 3.插件：head，bigdesk 4.部署4个节点：2个数据节点，1个主节点，1个备用主节点 部署请到 GitHub 下载 ES 2.3.0 版本 https://github.com/elastic/elasticsearch/tree/v2.3.0 解压请根据自己部署软件的习惯解压到合适目录，下面是我的本机目录： /Users/zhen/opt/es-cloud-2.3.0 es-cloud-2.3.0 文件夹放置的单机的4个节点目录，附上我的目录结构： 从图中大家也了解了，其实就是复制出4份来，只不过每个ES里面的配置不一样。 插件安装前面已经介绍过了，请看 这里 ，可以先安装master的插件，安转完成再复制就好了。 各个节点的配置主节点master： 123456789101112131415cluster.name: my-es#主节点node.name: masternode.master: true#数据节点node.data: falsenetwork.host: 0.0.0.0http.port: 9200transport.tcp.port: 9300#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 数据节点data-1： 123456789101112131415cluster.name: my-es#主节点node.name: data-1node.master: false#数据节点node.data: truenetwork.host: 0.0.0.0http.port: 9201transport.tcp.port: 9301#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 数据节点data-2： 123456789101112131415cluster.name: my-es#主节点node.name: data-2node.master: false#数据节点node.data: truenetwork.host: 0.0.0.0http.port: 9202transport.tcp.port: 9302#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 备用主节点： 123456789101112131415cluster.name: my-es#主节点node.name: client-1node.master: true#数据节点node.data: falsenetwork.host: 0.0.0.0http.port: 9203transport.tcp.port: 9303#集群节点列表discovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9303\",\"127.0.0.1:9301\",\"127.0.0.1:9302\"]#多播，单机的话无所谓了discovery.zen.ping.multicast.enabled: true#集群限制节点的个数node.max_local_storage_nodes: 10 启动启动节点，写到脚本里面执行，不用一条条的运行了。 1234567./es-node-master/bin/elasticsearch -d./es-node-data-1/bin/elasticsearch -d./es-node-data-2/bin/elasticsearch -d./es-node-client/bin/elasticsearch -d 查看集群状态： 测试假如我们挂掉主节点，再来看看我们的集群状态。 当我们挂掉了master，访问任意一个节点的head插件，来看集群状态。选举了client-1为主节点。 最后附上bigdesk的截图：","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Ik","slug":"Ik","permalink":"http://pzhen.github.io/tags/Ik/"},{"name":"集群","slug":"集群","permalink":"http://pzhen.github.io/tags/集群/"}]},{"title":"Maven - Mac 安装","slug":"Maven-Mac-安装","date":"2017-07-21T08:04:51.000Z","updated":"2017-07-21T09:49:08.000Z","comments":true,"path":"2017/07/21/Maven-Mac-安装/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Maven-Mac-安装/","excerpt":"","text":"1.下载maven http://mirror.bit.edu.cn/apache/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.zip 2.解压 unzip apache-maven-3.5.0-bin.zip 如果是tar.gz包 tar xzvf apache-maven-3.5.0-bin.tar.gz 3.配置环境变量 vim ~/.bash_profile 添加路径： export PATH=/路径/apache-maven-3.5.0/bin:$PATH 4.查看 mvn -version 官方install地址：http://maven.apache.org/install.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Maven","slug":"Linux/Maven","permalink":"http://pzhen.github.io/categories/Linux/Maven/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Maven","slug":"Maven","permalink":"http://pzhen.github.io/tags/Maven/"},{"name":"Java","slug":"Java","permalink":"http://pzhen.github.io/tags/Java/"}]},{"title":"Python 优先级队列","slug":"Python-优先级队列","date":"2017-07-21T07:22:32.000Z","updated":"2017-07-21T07:58:18.000Z","comments":true,"path":"2017/07/21/Python-优先级队列/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Python-优先级队列/","excerpt":"优先级队列是一种容器型数据结构，它能管理一队记录，并按照排序字段（例如一个数字类型的权重值）为其排序。由于是排序的，所以在优先级队列中你可以快速获取到最大的和最小的值。","text":"优先级队列是一种容器型数据结构，它能管理一队记录，并按照排序字段（例如一个数字类型的权重值）为其排序。由于是排序的，所以在优先级队列中你可以快速获取到最大的和最小的值。你可以认为优先级队列是一种修改过的普通队列：普通队列依据记录插入的时间来获取下一个记录，优先级队列依据优先级来获取下一个记录，而优先级取决于排序字段的值。 优先级队列经常用来解决调度问题，比如给更紧急的任务更高的优先级。 我们以操作系统的任务调度为例：高优先级的任务（比如实时游戏）应该先于低优先级的任务（比如后台下载软件更新）执行。通过在优先级队列中依据任务的紧急程度排序，我们能让最紧急的任务优先得到执行。 queue.PriorityQueue类 12345678910111213141516import Queueq = Queue.PriorityQueue()q.put((2,'code'))q.put((1,'eat'))q.put((3,'sleep'))while not q.empty(): next_item = q.get() print(next_item)# Result# (1,'eat')# (2, 'code')# (3, 'sleep') 这个优先级队列内部使用了heapq，所以它的时间复杂度和heapq是相同的。 不同的是PriorityQueue的操作是同步的，提供锁操作，支持并发的生产者和消费者。 依据使用场景，它可能很有用，也可能有点太大了。通常来说它的基于类接口要比heapq的基于函数的接口更友好。","categories":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/tags/Python/"},{"name":"队列","slug":"队列","permalink":"http://pzhen.github.io/tags/队列/"},{"name":"优先级队列","slug":"优先级队列","permalink":"http://pzhen.github.io/tags/优先级队列/"}]},{"title":"Hexo – 'Deployer not found'","slug":"Hexo-–-Deployer-not-found","date":"2017-07-21T06:03:27.000Z","updated":"2017-07-21T09:07:50.000Z","comments":true,"path":"2017/07/21/Hexo-–-Deployer-not-found/","link":"","permalink":"http://pzhen.github.io/2017/07/21/Hexo-–-Deployer-not-found/","excerpt":"","text":"重新部署了Hexo，结果无法部署，解决方法如下： 1npm install hexo-deployer-git --save","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://pzhen.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://pzhen.github.io/tags/Hexo/"}]},{"title":"Es – 集群生态总结","slug":"Elasticsearch-–-集群生态总结","date":"2017-07-20T09:05:22.000Z","updated":"2017-07-20T09:28:15.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-集群生态总结/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-集群生态总结/","excerpt":"","text":"分片算法:1shard = hash(routing) % number_of_primary_shards routing值是一个任意字符串，它默认是_id但也可以自定义，这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数的范围永远是0到number_of_primary_shards – 1，这个数字就是特定文档所在的分片。 这也解释了为什么主切片的数量只能在创建索引时定义且不能修改：如果主切片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。 所有的文档API（get、index、delete、bulk、update、mget）都接收一个routing参数，它用来自定义文档到分片的映射。自定义路由值可以确保所有相关文档.比如用户的文章,按照用户账号路由,就可以实现属于同一用户的文档被保存在同一分片上。 增删改（write）执行过程不管是索引，还是文档的write操作，它们必须在主分片上成功完成才能复制到相关的复制分片上,下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤： 1、客户端给Node 1发送新建、索引或删除请求。 2、节点使用文档的_id确定文档属于分片0。它转发请求到Node 3，分片0位于这个节点上。 3、Node 3在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1和Node 2的复制节点上。当所有的复制节点报告成功，Node 3报告成功到请求的节点，请求的节点再报告给客户端。 客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。 副本分片复制时的相关的参数说明:replication: 复制默认的值是sync。这将导致主分片得到复制分片的成功响应后才返回，如果你设置replication为async，请求在主分片上被执行后就会返回给客户端。它依旧会转发请求给复制节点，但你将不知道复制节点成功与否。 默认的sync复制允许Elasticsearch强制反馈传输。async复制可能会因为在不等待其它分片就绪的情况下发送过多的请求而使Elasticsearch过载。 consistency: 默认主分片在尝试写入时需要规定数量(quorum)或过半的分片（可以是主节点或复制节点）可用。这是防止数据被写入到错的网络分区。规定的数量计算公式如下：1int( (primary + number_of_replicas) / 2 ) + 1 consistency允许的值为one（只有一个主分片），all（所有主分片和复制分片）或者默认的quorum或过半分片。 注意number_of_replicas是在索引中的的设置，用来定义复制分片的数量，而不是现在活动的复制节点的数量。如果你定义了索引有3个复制节点，那规定数量是：int( (primary + 3 replicas) / 2 ) + 1 = 3 但如果你只有2个节点，那你的活动分片不够规定数量，也就不能索引或删除任何文档。 注意: 新索引默认有1个复制分片，这意味着为了满足quorum的要求需要两个活动的分片。当然，这个默认设置将阻止我们在单一节点集群中进行操作。为了避开这个问题，规定数量只有在number_of_replicas大于一时才生效。 timeout： 当分片副本不足时Elasticsearch会等待更多的分片出现。默认等待一分钟。如果需要，你可以设置timeout参数让它终止的更早：100表示100毫秒，30s表示30秒。 集群生态:1.同集群中节点之间可以扩容缩容, 2.主分片的数量会在其索引创建完成后修正，但是副本分片的数量会随时变化。 3.相同的分片不会放在同一个节点上. 集群健康:在Elasticsearch集群中可以监控统计很多信息，但是只有一个是最重要的时集群健康(cluster health)。Es中用三种颜色状态表示:green，yellow，red. Green：所有主分片和副本分片都可用 Yellow：所有主分片可用，但不是所有副本分片都可用 Red：不是所有的主分片都可用； 单机多节点来了解ES的高可用创建单集群节点如图我们的单点集群: 实例中我们创建一个索引dobbyindex.一个索引默认指派5个主分片,实例中我们设定4个主分片和2个复制分片（每个主分片有2个复制分片对应）： 1234567PUT /dobbyindex&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 4, &quot;number_of_replicas&quot;: 2 &#125;&#125; 创建后索引如图: 在节点es-node1中片的存放如下: 我们的主分片都被分配到了es-node1.但是我们的8个复制分片还没有被分配到节点上, 此时的集群健康状况如下: cluster health: yellow (4 of 12)对应的详细信息为: 123456789101112&#123; &quot;cluster_name&quot;: &quot;elasticsearch-cluster-centos&quot;, &quot;status&quot;: &quot;yellow&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 1, &quot;number_of_data_nodes&quot;: 1, &quot;active_primary_shards&quot;: 4, &quot;active_shards&quot;: 4, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 8&#125; 意味着所有的主分片(primary shards)启动并且运行了,集群已经可以成功的接受任意请求,但是副本分片(replica shards)还没有全部可用。事实上所有的8个副本分片现在是unassigned（未分配）状态,即它们还未被分配给节点,在同一个节点上保存相同的数据副本是没有必要的，如果这个节点故障了，那所有的数据副本也会丢失。现在我们的集群已经功能完备，但是依旧存在因硬件故障而导致的数据丢失的风险。 增加故障转移上面实例中的集群有单点故障的风险,没有数据冗余备份。我们可以扩展节点来保护数据不被丢失.只要第二个节点与第一个节点有相同的cluster.name(实例中为elasticsearch-cluster-centos)，它就能自动发现并加入第一个节点的集群。 如果没有，检查日志找出哪里出了问题。这可能是网络广播被禁用，或者防火墙阻止了节点通信。 当我们启动第二个节点之后:集群中的分片结构图如下: 虽然,已经有4个副本分片被分陪到es-node2节点上来了，但是按照我们定义的副本分片的值为2, 还有4个分片处于未分片状态,此时对于我们设定的参数来说,集群的健康值还是所有主分片可用，但不是所有复制分片都可用. 对应的集群健康状况: cluster health: yellow (8 of 12) 对应的详细信息为:12345678910111213&#123; &quot;cluster_name&quot;: &quot;elasticsearch-cluster-centos&quot;, &quot;status&quot;: &quot;yellow&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 4, &quot;active_shards&quot;: 8, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 4 &#125; 所以我们还需要一个节点来分片这些副本分片,使集群达到高可用,再增加集群节点: 当我们启动第三个节点之后,整个集群上的分片都进行了有效分配,从图中可以看出.es-node1为这个集群生态中选举出来的主(master),es-node2和es-node3为集群生态中的slave(从). 这样,一些新的被索引的文档将首先被存储在主分片中，然后平行复制到关联的复制节点上。这可以确保我们的数据在主节点和复制节点上都可以被检索。 此时集群的健康状态如下： cluster health: green (12 of 12)对应的详细信息为： 12345678910111213&#123; &quot;cluster_name&quot;: &quot;elasticsearch-cluster-centos&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 3, &quot;number_of_data_nodes&quot;: 3, &quot;active_primary_shards&quot;: 4, &quot;active_shards&quot;: 12, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0 &#125; 下图为,节点es-node3加入时,分片分配过程中截取的临时图. 模拟节点宕机,集群主从重新选举上图中我们的主节点为es-node1,如果主节点宕掉后,会怎样呢. 如图:主节点对应的进程号7421,干掉它，此时es集群生态发生了如下变化,如图: es-node3被选举为主节点,es-node2为从节点,主分片与副本分片也变化了,主分片放置在了es-node2上,副本分片放置到了es-node3上,因为分片没有完全被分配,所以集群的健康状态变为yellow(所有主分片可用，但不是所有复制分片都可用),然后我们重启es-node1节点. 如图,重启后健康状态恢复到green,但是集群主从变化了,且主分片的位置也变化了. 模拟扩展节点 实例2中我们的集群已经达到高可用状态,对应的索引分片如图.此时我们想要扩展集群继续增加节点时,我们的分片会怎样呢,接下来我们再增加一个扩展节点es-node4. 如图:扩容后,可以看到片进行了重新分片,节点es-node1和es-node3上分别持有主分片。es-node2,es-node3,es-node4持有副本分片，由于笔者模拟过程中有主节点宕机操作, 所以从图中可以看出,新的生态集群中es-node4为主节点.对应的各个集群存储中包含的片分布信息如下: 这种状态下的片也是完全分配，green(所有主要和复制的分片都可用). 动态缩小或者扩容副本片数量副本节点的数量可以在运行中的集群中动态的变更，这允许我们可以根据需求扩大或者缩小规模。 比如我们执行一次缩小规模操作: 12345678PUT /dobbyindex/_settings&#123; &quot;number_of_replicas&quot; : 1&#125;执行结果返回:&#123; &quot;acknowledged&quot;: true&#125; 这时,我们看到片的信息分又重新做了调整: 主分片分布在节点es-node1,es-node3,es-node4上.从分片分布在es-node2,es-node3,es-node4上.","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"集群","slug":"集群","permalink":"http://pzhen.github.io/tags/集群/"}]},{"title":"Es – 倒排索引","slug":"Elasticsearch-–-倒排索引","date":"2017-07-20T08:38:47.000Z","updated":"2017-07-20T09:27:32.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-倒排索引/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-倒排索引/","excerpt":"","text":"Lucene 简介Lucene是Apache软件基金会中一个开放源代码的全文搜索引擎工具包，是一个全文搜索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文搜索引擎。Lucene最初是由Doug Cutting所撰写的，是一位资深全文索引/搜索专家，曾经是V-Twin搜索引擎的主要开发者，后来在Excite担任高级系统架构设计师，目前从事于一些Internet底层架构的研究。 Lucene 采用倒排索引倒排索引源于实际应用中需要根据属性的值来查找记录。 这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引（inverted index）。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件（inverted file）。 Lucene 如何构建倒排索引1.获取关键词由于倒排序是根据关键字索引来定位记录的，所以要先获取关键词。比如一篇文章，也就是一串字符串，要获取所有的分词（关键字），如果是英文字符串也就是所有单词，中文则依赖中文分词器来获取所有词语，然而不管英文还是中文有些词是无意义的比如“is”，“in”，“的”等等过滤掉，标点符号过滤掉，大小写统一，等等经过一系列的过滤筛选后得到分词，也就是我们的关键字。 例子： 假设有两篇文章1和文章2： 文章1的内容为：Tom lives in Guangzhou，I live in Guangzhou too.文章2的内容为：He once lived in Shanghai. 在Lucene中以上措施由Analyzer类完成分词处理，结果如下： 文章1的所有关键词为：[tom][live][guangzhou][i][live][guangzhou]文章2的所有关键词为：[he][live][shanghai] 2.建立倒排索引有了关键词后，我们就可以建立倒排索引了。上面的对应关系是：“文章号”对“文章中所有关键词”。倒排索引把这个关系倒过来，变成：“关键词”对“拥有该关键词的所有文章号”。 通常仅知道关键词在哪些文章中出现还不够，我们还需要知道关键词在文章中出现的次数和位置，加上位置与出现次数后如下： 以上就是Lucene索引结构中最核心的部分。我们注意到关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以用二元搜索算法快速定位关键词。 3.实现倒排索引实现时，Lucene将上面三列分别作为词典文件（Term Dictionary）、频率文件（frequencies）、位置文件（positions）保存。其中词典文件不仅保存了每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。Lucene中使用了field的概念，用于表达信息所在位置（如标题中、文章中、URL中），在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息，因为每个关键字一定属于一个或多个field。 4.压缩算法为了减小索引文件的大小，Lucene对索引还使用了压缩技术。首先，对词典文件中的关键词进行了压缩，关键词压缩为&lt;前缀长度，后缀&gt;，例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为。其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减少数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。 5.查询假设要查询单词“live”，Lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。词典通常非常小，因而，整个过程的时间是毫秒级的。而用普通的顺序匹配算法，不建索引，而是对所有文章的内容进行字符串匹配，这个过程将会相当缓慢，当文章数目很大时，时间往往是无法忍受的。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"倒排序","slug":"倒排序","permalink":"http://pzhen.github.io/tags/倒排序/"},{"name":"Lucene","slug":"Lucene","permalink":"http://pzhen.github.io/tags/Lucene/"}]},{"title":"Es – Ik 分词器","slug":"Elasticsearch-–-Ik-分词器","date":"2017-07-20T08:24:42.000Z","updated":"2017-07-20T09:28:21.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-Ik-分词器/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-Ik-分词器/","excerpt":"","text":"下载ik分词器包1https://github.com/medcl/elasticsearch-analysis-ik 解压1unzip elasticsearch-analysis-ik-master.zip 打包123cd elasticsearch-analysis-ik-mastermvn package 打包后的文件在elasticsearch-analysis-ik-master/target/目录下 集成到ES在elasticsearch-5.3.0/plugins下创建目录 ik1copy and unzip target/releases/elasticsearch-analysis-ik-5.3.0.zip to your-es-root/plugins/ik 然后删除 zip文件1rm -f elasticsearch-analysis-ik-5.3.0.zip 重启ES1./bin/elasticsearch 添加数据测试创建索引1curl -XPUT http://localhost:9200/user 创建mapping1234567891011121314151617181920curl -XPOST http://localhost:9200/user/fulltext/_mapping -d&apos;&#123; &quot;fulltext&quot;: &#123; &quot;_all&quot;: &#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot;, &quot;term_vector&quot;: &quot;no&quot;, &quot;store&quot;: &quot;false&quot; &#125;, &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot;, &quot;include_in_all&quot;: &quot;true&quot;, &quot;boost&quot;: 8 &#125; &#125; &#125;&#125;&apos; 我的理解就是solr中的分词器 的 fieldType。 添加文档123456789101112curl -XPOST http://localhost:9200/user/fulltext/1 -d&apos;&#123;&quot;content&quot;:&quot;美国留给伊拉克的是个烂摊子吗&quot;&#125;&apos;curl -XPOST http://localhost:9200/user/fulltext/2 -d&apos;&#123;&quot;content&quot;:&quot;公安部：各地校车将享最高路权&quot;&#125;&apos;curl -XPOST http://localhost:9200/user/fulltext/3 -d&apos;&#123;&quot;content&quot;:&quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot;&#125;&apos;curl -XPOST http://localhost:9200/user/fulltext/4 -d&apos;&#123;&quot;content&quot;:&quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot;&#125;&apos; 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556curl -XPOST http://localhost:9200/user/fulltext/_search?pretty -d&apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;content&quot; : &quot;中国&quot; &#125;&#125;, &quot;highlight&quot; : &#123; &quot;pre_tags&quot; : [&quot;&lt;tag1&gt;&quot;, &quot;&lt;tag2&gt;&quot;], &quot;post_tags&quot; : [&quot;&lt;/tag1&gt;&quot;, &quot;&lt;/tag2&gt;&quot;], &quot;fields&quot; : &#123; &quot;content&quot; : &#123;&#125; &#125; &#125;&#125;&apos;结果集&#123; &quot;took&quot; : 7, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 4.278213, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;user&quot;, &quot;_type&quot; : &quot;fulltext&quot;, &quot;_id&quot; : &quot;4&quot;, &quot;_score&quot; : 4.278213, &quot;_source&quot; : &#123; &quot;content&quot; : &quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot; &#125;, &quot;highlight&quot; : &#123; &quot;content&quot; : [ &quot;&lt;tag1&gt;中国&lt;/tag1&gt;驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&quot; ] &#125; &#125;, &#123; &quot;_index&quot; : &quot;user&quot;, &quot;_type&quot; : &quot;fulltext&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 2.2110996, &quot;_source&quot; : &#123; &quot;content&quot; : &quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&quot; &#125;, &quot;highlight&quot; : &#123; &quot;content&quot; : [ &quot;中韩渔警冲突调查：韩警平均每天扣1艘&lt;tag1&gt;中国&lt;/tag1&gt;渔船&quot; ] &#125; &#125; ] &#125;&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Ik","slug":"Ik","permalink":"http://pzhen.github.io/tags/Ik/"}]},{"title":"Es – 核心概念","slug":"Elasticsearch-–-核心概念","date":"2017-07-20T08:07:51.000Z","updated":"2017-07-20T09:28:08.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-核心概念/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-核心概念/","excerpt":"","text":"接近实时（NRT）Elasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟（通常是1秒）。 集群（cluster）一个集群就是由一个或多个节点组织在一起，它们共同持有你整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群。在产品环境中显式地设定这个名字是一个好习惯，但是使用默认值来进行测试/开发也是不错的。 节点（node）一个节点是你集群中的一个服务器，作为集群的一部分，它存储你的数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。 一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。 在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。 索引（index）一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。 在一个集群中，如果你想，可以定义任意多的索引。 类型（type）在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可以为评论数据定义另一个类型。 文档（document）一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。 在一个index/type里面，只要你想，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须被索引/赋予一个索引的type。 分片和复制（shards &amp; replicas）一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。 为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。 分片之所以重要，主要有两方面的原因： – 允许你水平分割/扩展你的内容容量– 允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，有两个主要原因：– 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。– 扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行 总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。 默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。 下面附上一张关于索引，类型，文档的三者关系图，便于很好的理解： 集群的架构简图：","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"}]},{"title":"Es – 安装","slug":"Elasticsearch-–-安装","date":"2017-07-20T07:54:38.000Z","updated":"2017-07-20T09:28:00.000Z","comments":true,"path":"2017/07/20/Elasticsearch-–-安装/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Elasticsearch-–-安装/","excerpt":"","text":"由于高版本提高了安全级别，不能采用root账户启动. 下载下载地址：https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.3.0.zip 解压后执行1./bin/elasticsearch 错误处理错误提示123456Exception in thread &quot;main&quot; java.lang.RuntimeException: don&apos;t run elasticsearch as root. at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:93) at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:144) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:285) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)Refer to the log for complete error details. 解决错误因为版本的问题，最新的版本安全级别提高了，不允许采用root帐号启动，所以我们要添加一个用户。 12345678910111213#添加一个用户：elasticsearch$useradd elasticsearch#给用户elasticsearch设置密码，连续输入2次$passwd elasticsearch#创建一个用户组 esgroupadd es#分配 elasticsearch 到 es 组usermod -G elasticsearch es#这里注意下，如果提示用户“es”不存在，那么是因为服务器版本问题，你可以换成 usermod -G es elasticsearch ,也就是用户和用户组对调一下使用。#在elasticsearch 根目录下，给定用户权限。-R表示逐级（N层目录） ， * 表示 任何文件chown -R elasticsearch.es *#切换到elasticsearch用户su elasticsearch 如果不按上面的给用户 elasticsearch 分配权限目录。那么会报下面的错。 123456789101112131415161718192021java.io.FileNotFoundException: /home/es/elasticsearch-2.2.0/logs/elasticsearch.log (Permission denied) at java.io.FileOutputStream.open(Native Method) at java.io.FileOutputStream.(FileOutputStream.java:221) at java.io.FileOutputStream.(FileOutputStream.java:142) at org.apache.log4j.FileAppender.setFile(FileAppender.java:294) at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165) at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:223) at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307) at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172) at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104) at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842) at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768) at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648) at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514) at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440) at org.elasticsearch.common.logging.log4j.LogConfigurator.configure(LogConfigurator.java:128) at org.elasticsearch.bootstrap.Bootstrap.setupLogging(Bootstrap.java:204) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:258) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)log4j:ERROR Either File or DatePattern options are not set for appender [file].log4j:ERROR setFile(null,true) call failed. 修改配置文件12345678$ vi config/elasticsearch.yml#cluster namecluster.name: sojson-application#节点名称node.name: node-1#绑定IP和端口network.host: 123.88.88.88http.port: 9200 后台运行1./bin/elasticsearch -d 查找进程1ps -ef | grep elasticsearch","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://pzhen.github.io/tags/Elasticsearch/"},{"name":"Es","slug":"Es","permalink":"http://pzhen.github.io/tags/Es/"},{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"}]},{"title":"Vim colorschemes","slug":"Vim-colorschemes","date":"2017-07-20T06:52:07.000Z","updated":"2017-07-20T06:54:25.000Z","comments":true,"path":"2017/07/20/Vim-colorschemes/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Vim-colorschemes/","excerpt":"","text":"最近给vim换了个主题?，里面有丰富的主题，也可以去web页面去定制。给分享下： 12官方地址：http://bytefluent.com/vivify/GitHub：https://github.com/flazz/vim-colorschemes 我的设置是1colorscheme murphy 希望大家喜欢。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Vim","slug":"Linux/Vim","permalink":"http://pzhen.github.io/categories/Linux/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"http://pzhen.github.io/tags/Vim/"},{"name":"colorschemes","slug":"colorschemes","permalink":"http://pzhen.github.io/tags/colorschemes/"}]},{"title":"Shell – item2 配色","slug":"Shell-–-item2-配色","date":"2017-07-20T03:29:58.000Z","updated":"2017-07-21T09:47:02.000Z","comments":true,"path":"2017/07/20/Shell-–-item2-配色/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Shell-–-item2-配色/","excerpt":"","text":"下载请到 https://github.com/mbadolato/iTerm2-Color-Schemes 下载。 1git clone https://github.com/mbadolato/iTerm2-Color-Schemes.git 安装To install: Launch iTerm 2. Get the latest version at iterm2.com Type CMD+i (⌘+i) Navigate to Colors tab Click on Color Presets Click on Import Select the .itermcolors file(s) of the scheme(s) you’d like to use Click on Color Presets and choose a color scheme","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://pzhen.github.io/tags/Mac/"},{"name":"Iterm2","slug":"Iterm2","permalink":"http://pzhen.github.io/tags/Iterm2/"}]},{"title":"Python 中文编码问题","slug":"Python-中文编码问题","date":"2017-07-20T03:10:21.000Z","updated":"2017-07-20T03:23:13.000Z","comments":true,"path":"2017/07/20/Python-中文编码问题/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Python-中文编码问题/","excerpt":"","text":"文件编码Python中默认的编码格式是 ASCII 格式，在没修改编码格式时无法正确打印汉字，所以在读取中文时会报错。 解决方法为只要在文件开头加入 # -- coding: UTF-8 -- 或者 #coding=utf-8 就行了。 123#!/usr/bin/python# -*- coding: UTF-8 -*-print &quot;你好，世界&quot;; 所以如果大家在学习过程中，代码中包含中文，就需要在头部指定编码。 注意：Python3.X 源码文件默认使用utf-8编码，所以可以正常解析中文，无需指定 UTF-8 编码。 如果你使用编辑器，同时需要设置好编辑器的编码，如 Pycharm 设置步骤： 1.进入 file &gt; Settings，在输入框搜索 encoding。 2.找到 Editor &gt; File encodings，将 IDE Encoding 和 Project Encoding 设置为utf-8。 编码之间的转换例如 类Unix系统上编写的python，如果放到windows下面执行，比如输出的信息包含中文，就需要转换了，不管是 gb2312 转 utf8 还是 utf8 转 gb2312 都需要现将字符串转换成Unicode的编码，然后再转换成正确的编码例如：1print &quot;2.结算表格读取完成&quot;.decode(&apos;utf-8&apos;).encode(&apos;gb2312&apos;) 将输出的提示语utf8转成gb2312。 print list 中文如果查看print list 的时候里面中文也显示正确，方便调试可这样：1import uniout 引入该包 就可以显示list中的中文了。","categories":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://pzhen.github.io/tags/Python/"}]},{"title":"Php 一致性哈希","slug":"Php-实现一致性哈希包含虚拟节点","date":"2017-07-20T02:43:35.000Z","updated":"2017-07-21T06:14:28.000Z","comments":true,"path":"2017/07/20/Php-实现一致性哈希包含虚拟节点/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Php-实现一致性哈希包含虚拟节点/","excerpt":"","text":"之前看到Es的分片路由机制，想到了分布式的一致性哈希， 从无虚拟哈希环，到添加上虚拟哈希环。 下面是php的实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129&lt;?phpfunction myHash($str) &#123; $hash = 0; $s = md5($str); $seed = 5; $len = 32; for ($i = 0; $i &lt; $len; $i++) &#123; $hash = ($hash &lt;&lt; $seed) + $hash + ord($s&#123;$i&#125;); &#125; return $hash &amp; 0x7FFFFFFF;&#125;class ConsistentHash &#123; #每个物理节点生成虚拟节点个数 public $virtual_num = 300; // server列表 public $_server_list = array(); // 延迟排序，因为可能会执行多次addServer private $_layze_sorted = FALSE; #server物理节点 public function addServer($server) &#123; $hash = myHash($server); $this-&gt;_layze_sorted = FALSE; if (!isset($this-&gt;_server_list[$hash])) &#123; $this-&gt;_server_list[$hash] = $server; &#125; return $this; &#125; #server虚拟节点 public function addServerVir($server) &#123; for ($i = 1; $i &lt;= $this-&gt;virtual_num; $i++) &#123; $hash_key = myHash($server.\"#\".$i); if(!isset($this-&gt;_server_list[$hash_key])) &#123; $this-&gt;_server_list[$hash_key] = $server; &#125; &#125; return $this; &#125; public function find($key) &#123; // 排序 if (!$this-&gt;_layze_sorted) &#123; ksort($this-&gt;_server_list); $this-&gt;_layze_sorted = TRUE; &#125; #print_r($this-&gt;_server_list);exit(); $hash = myHash($key); $len = sizeof($this-&gt;_server_list); if ($len == 0) &#123; return FALSE; &#125; $keys = array_keys($this-&gt;_server_list); #server hash 值 $values = array_values($this-&gt;_server_list); #server 地址 if ($hash &lt;= $keys[0] || $hash &gt;= $keys[$len - 1]) &#123; return $values[0]; &#125; foreach ($keys as $key=&gt;$pos) &#123; $next_pos = NULL; if (isset($keys[$key + 1])) &#123; $next_pos = $keys[$key + 1]; &#125; if (is_null($next_pos)) &#123; return $values[$key]; &#125; // 区间判断 if ($hash &gt;= $pos &amp;&amp; $hash &lt;= $next_pos) &#123; return $values[$key]; &#125; &#125; &#125;&#125;$consisHash = new ConsistentHash();#物理节点hash环#$consisHash-&gt;addServer(\"server1\")-&gt;addServer(\"server2\")-&gt;addServer(\"server3\")-&gt;addServer(\"server4\");#带虚拟节点的hash环$consisHash-&gt;addServerVir(\"server1\")-&gt;addServerVir(\"server2\")-&gt;addServerVir(\"server3\")-&gt;addServerVir(\"server4\");$total_server1_num = $total_server2_num = $total_server3_num = $total_server4_num = 0;for ($i=1; $i &lt;= 200000; $i++) &#123; # code... $key = uniqid(TRUE,TRUE); $server_name = $consisHash-&gt;find($key); if($server_name == \"server1\")&#123; $total_server1_num += 1; &#125; if($server_name == \"server2\")&#123; $total_server2_num += 1; &#125; if($server_name == \"server3\")&#123; $total_server3_num += 1; &#125; if($server_name == \"server4\")&#123; $total_server4_num += 1; &#125;&#125;echo \"server1 num :\" .$total_server1_num .\"\\n\";echo \"server2 num :\" .$total_server2_num .\"\\n\";echo \"server3 num :\" .$total_server3_num .\"\\n\";echo \"server4 num :\" .$total_server4_num .\"\\n\"; 参考资料 flexihash","categories":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/categories/Php/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"一致性Hash","slug":"一致性Hash","permalink":"http://pzhen.github.io/tags/一致性Hash/"}]},{"title":"Redis - PHP7扩展","slug":"Redis-PHP7扩展","date":"2017-07-20T02:39:26.000Z","updated":"2017-07-21T09:41:10.000Z","comments":true,"path":"2017/07/20/Redis-PHP7扩展/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Redis-PHP7扩展/","excerpt":"","text":"下载 https://github.com/phpredis/phpredis/tree/php7 解压 unzip phpredis-php7.zip phpize #用phpize生成configure配置文件 ./configure 配置 make #编译 make install #安装 安装完成后将出现的安装路径添加到php.ini中: extension_dir = “/usr/lib/php/20151012” extension = redis.so 重启服务器,查看phpinfo,是不是搞定.","categories":[{"name":"Redis","slug":"Redis","permalink":"http://pzhen.github.io/categories/Redis/"}],"tags":[{"name":"Php","slug":"Php","permalink":"http://pzhen.github.io/tags/Php/"},{"name":"Redis","slug":"Redis","permalink":"http://pzhen.github.io/tags/Redis/"}]},{"title":"Jdk - Ubuntu安装","slug":"Jdk-Ubuntu安装","date":"2017-07-20T02:32:47.000Z","updated":"2017-07-21T09:50:46.000Z","comments":true,"path":"2017/07/20/Jdk-Ubuntu安装/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Jdk-Ubuntu安装/","excerpt":"","text":"Ubuntu 下安装 jdk 1.解压1sudo tar zxvf ./jdk-7u45-linux-x64.tar.gz 2.环境变量12345vi ~/.bashrc 或者 ~/.zshrcexport JAVA_HOME=/opt/Java/jdk/jdk1.7 export CLASSPATH=$&#123;JAVA_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 3.立即生效1source ~/.bashrc","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Jdk","slug":"Linux/Jdk","permalink":"http://pzhen.github.io/categories/Linux/Jdk/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Jdk","slug":"Jdk","permalink":"http://pzhen.github.io/tags/Jdk/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://pzhen.github.io/tags/Ubuntu/"}]},{"title":"Shell – Mac zsh","slug":"Shell-–-Mac-zsh","date":"2017-07-20T02:07:00.000Z","updated":"2017-07-21T09:45:25.000Z","comments":true,"path":"2017/07/20/Shell-–-Mac-zsh/","link":"","permalink":"http://pzhen.github.io/2017/07/20/Shell-–-Mac-zsh/","excerpt":"","text":"目前常用的 Linux 系统和 OS X 系统的默认 Shell 都是 bash，但是真正强大的 Shell 是深藏不露的 zsh， 这货绝对是马车中的跑车，跑车中的飞行车，史称『终极 Shell』，但是由于配置过于复杂，所以初期无人问津，很多人跑过来看看 zsh 的配置指南，什么都不说转身就走了。直到有一天，国外有个穷极无聊的程序员开发出了一个能够让你快速上手的zsh项目，叫做「oh my zsh」，这玩意就像「X天叫你学会 C++」系列，可以让你神功速成，而且是真的。 地址：https://github.com/robbyrussell/oh-my-zsh","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://pzhen.github.io/tags/Mac/"},{"name":"Zsh","slug":"Zsh","permalink":"http://pzhen.github.io/tags/Zsh/"}]},{"title":"","slug":"Linux下-ssh-自动登录脚本","date":"2017-07-19T14:58:13.000Z","updated":"2017-07-21T09:05:35.000Z","comments":true,"path":"2017/07/19/Linux下-ssh-自动登录脚本/","link":"","permalink":"http://pzhen.github.io/2017/07/19/Linux下-ssh-自动登录脚本/","excerpt":"","text":"title: Linux下 SSH 登录脚本","categories":[],"tags":[]},{"title":"Shell – SSH自动登录","slug":"Shell-–-SSH自动登录","date":"2017-07-19T14:58:13.000Z","updated":"2017-07-21T09:05:42.000Z","comments":true,"path":"2017/07/19/Shell-–-SSH自动登录/","link":"","permalink":"http://pzhen.github.io/2017/07/19/Shell-–-SSH自动登录/","excerpt":"","text":"最近由于频繁操作vps，发现每次输入密码太费劲，所以写了个自动登录shell脚本。 1.创建脚本 xxx.sh12345#!/usr/bin/expectset timeout 30spawn ssh -l root ip地址expect &quot;password:&quot;send &quot;密码\\r&quot; 2.将脚本目录加入环境变量export PATH=/Users/zhen/Documents/shell:$PATH这样一来在命令行随时可以调用脚本远程登录。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"SSH","slug":"SSH","permalink":"http://pzhen.github.io/tags/SSH/"}]},{"title":"Vim 常用命令","slug":"Vim-常用命令","date":"2017-07-19T09:42:58.000Z","updated":"2017-07-19T14:29:39.000Z","comments":true,"path":"2017/07/19/Vim-常用命令/","link":"","permalink":"http://pzhen.github.io/2017/07/19/Vim-常用命令/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778----------------------------光标移动-------------------------h 向左移动一个字符j 向下移动一行k 向上移动一行l 向右移动一个字符 control f 向下翻一页control b 向上翻一页control d 向下翻半页control u 向上翻半页 + 非空格下一行- 非空格上一行 n + 空格 移动n个字符0 移动到当前行第一个字符处$ 移动到当前行最后一个字符处G 移动到最后一行nG 跳到n行gg 第一行 n 回车 向下n行?keyword 向上查找 配合 n N 来上下查找/keyword 向下查找 配合 n N 来上下查找 :n1,n2s/keyword1/keyword2/g 在n1到n2行之间，查找keyword1并且替换成keyword2:1,$s/keyword1/keyword2/g 同上只不过是从1-最后一行:n1,n2/keyword1/keyword2/gc 只不过要确认后才替换 -----------------------------粘贴复制------------------------x 向后删除一个字符X 向前删除一个字符nx 连续向后删除n个字符dd 删除当前行ndd 删除向下n行 d1G 删除光标之前所有dG 删除光标到最后d$ 删除光标到行末d0 删除光标行首 yy 复制当前航nyy 向下复制n行y1G 复制光标到行首yG 复制光标到最后一行y0 复制光标到行首y$ 复制光标到行末 p 光标下一行粘贴P 光标上一行粘贴 ---------------------------------插入------------------------i 光标位置插入I 当前行非空第一个字符处插入a 光标处下一个字符插入A 当前行最后一个字符插入o 下一行插入o 上一行插入 :w filename 保存到另一个文件:r filename 读取文件内容到当前 :! command 暂时离开vim 执行命令---------------------区块选择-------------------------------v 字符区块选择V 行区块选择y 复制区块d 删除区块contrl + v 范围区块区块选择下 按 = 键 自动排版，代码会自动排版--------------------多文件同时编辑--------------------------vim filename1 filename2:n 下一个文件:N 上一个文件:files 打开的文件列表-------------------分屏---------------------:sp filenamectrl + w 来切换光标","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Vim","slug":"Linux/Vim","permalink":"http://pzhen.github.io/categories/Linux/Vim/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/tags/Linux/"},{"name":"Vim","slug":"Vim","permalink":"http://pzhen.github.io/tags/Vim/"}]},{"title":"Shell – Svn Log","slug":"Shell-–-Svn-Log","date":"2017-07-19T08:44:22.000Z","updated":"2017-07-21T09:02:48.000Z","comments":true,"path":"2017/07/19/Shell-–-Svn-Log/","link":"","permalink":"http://pzhen.github.io/2017/07/19/Shell-–-Svn-Log/","excerpt":"","text":"1.命令繁琐由于每次查看log需要输入好长的命令，在这里写成shell，方便许多。 1234567891011121314151617user_name=$1few_days_ago=$2if [ ! -n &quot;$user_name&quot; ]then user_name=&apos;xxxxxxxxxxxx&apos;fiif [ ! -n &quot;$few_days_ago&quot; ]then few_days_ago=30fistart_time=`date -v -&quot;$few_days_ago&quot;d +%Y-%m-%d`end_time=`date -v +1d +%Y-%m-%d`svn log -r &#123;$start_time&#125;:&#123;$end_time&#125; -v | sed -n &quot;/$user_name/,/--$/ p&quot; 2.使用方法:将shell加入环境变量，在项目里面: 1└─[$] &lt;&gt; svnlog.sh username days 3.默认参数如果不传参数默认脚本中username,30天的log。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pzhen.github.io/categories/Linux/"},{"name":"Shell","slug":"Linux/Shell","permalink":"http://pzhen.github.io/categories/Linux/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://pzhen.github.io/tags/Shell/"},{"name":"Svn","slug":"Svn","permalink":"http://pzhen.github.io/tags/Svn/"}]}]}